---
title: "Establishing causation in an observational design"
format: 
  revealjs:
    slide-number: true
    embed-resources: true
editor: source
---

## Causation and observational designs

-   Observational designs CAN establish a causal relationship
    -   Just requires more work
    -   Control for confounding
    -   Bring in external evidence
-   Hill's nine criteria (strength, consistency, specificity, temporality, biological gradient, plausibility, experiment, analogy)

::: notes

Your book states very strongly that only randomized trials can establish a cause and effect relationship. Quasi-experiments can sometimes suggest or hint at a cause and effect relationship. And non-experimental studies are pretty much incapable of anything.

This persective is held by many in the research community, but it is wrong, wrong, wrong. 

Observational designs can establish a causal relationship. Let me repeat this, because it is important. Observational designs can establish a causal relationship.

You just have to work a bit harder at it. Confounding, for example, is a serious problem for all observational studies, but there are tools like matching that can control for confounding during the design phase, or propensity score analysis, that can control for confounding during the analysis phase. You don't, necessarily have to resort to these approaches in a randomized trial (though they can't hurt). The point is that pretty much any reasonable randomized trial can establish a causal relationship. But in observational studies, only the very best studies can establish a causal relationship.

The other thing about observational studies is that there is strength in numbers. It is usually not just one study that establishes a cause and effect relationship. It is a series of studies. So your current observational study has to rely on information external to that study because by itself, it may not be strong enough.

I want to review Sir Austin Bradford Hill's criteria for establishing a causal relationship. He wrote a landmark paper in 1965 in the midst of the crisis in the research community about the link between smoking and lung cancer (more on that in a bit). He looked at the evidence that had accumulated and elucidated nine factors that you can use to help establish a causal relationship. None of these by themselves is sufficient, but a reasonable combination of them makes your argument quite persuasive.

:::

## Hill's criteria, strength

-   Strength
    -   Large effects can only be overturned by large confounders.
    -   Weak effects can still be real

::: notes

Hill identified the strength of the association as being the most critical factor. The reason for this is that a strong effect could only be overturned by a strong confounder. A weak confounder would only attenuate things a bit. If you want to hypothesize that a third factor among smokers (poor diet, dangerous work conditions, or lack of exercise) could cause the ten to twenty fold increase in the risk of lung cancer, that third factor would have to increase the risk of lung cancer by more ten or twenty fold.

Keep in mind, though, that weak effects can still be real. There was some criticism of a government report that said that the number of deaths due to smoking was around 450 thousand people per year. The critics dissected this number and said, we'll allow you the deaths due to cancer, but not for other factors like stroke and heart attacks, because these only showed a two fold or smaller increase in risk. It turns out that these other ways that smoking can kill you are very real, but because these causes of death (unlike lung cancer) are fairly common in the general population, you can't just get a large increase in risk. If 30% of the public dies from heart attacks, a ten fold increase is just impossible.

When the association is small, you don't totally disregard it. You just have to rely on some of the other criteria.

The other point, that has been made in many settings is that a large effect can be easily produced by a seriously flawed study. Paul Rosenbaum, in his book, Observational Studies discusses a non-randomized study conducted by Linus Pauling that showed a four fold increase in the survival times in patients with advanced cancer who received mega-doses of Vitamin C, and then points out the serious flaw that caused this finding.

:::

## Hill's criteria, consistency

-   Consistency
    -   Replication across DIFFERENT study types

::: notes

Consistency is also important. A single positive result in a single observational study could possibly be the result of various biases. A second positive result in a second study that is substantially different than the first study, could possibly be the result of a different set of biases. But by the time the third result comes along, in a study different that the first two, it becomes awfully hard to argue that there is a third set of biases. Biases can work in both directions, and it would be rare that all of these biases would conspire to work together towards a common goal.

Now, if the same study is replicated more or less consistently, then replication doesn't help that much.

:::

## Hill's criteria, specificity

-   Specificity
    -   Multiple cures or common bias?
    -   Deliberate inclusion of negative outcomes
    -   Exceptions: aspirin, smoking
  
::: notes

Specificity means that a treatment cures one and only one disease. If it appears to cure a multitude of diseases, then what is probably happening is that there is a bias (maybe selection bias?) that is causing the exposure group to be healthier than the control group. If an exposure is causing a multitude of problems, maybe a bias is causing the exposure group to be sicker than the control group.

You can rule out a healthier or sicker exposure group if you show that only one outcome (or only a small number of outcomes) is changed between the exposed and unexposed groups. You can take advantage of this by deliberately including outcome measures that you would expect to be negative.

Suppose you are testing whether toll booth workers suffer problems from CO poisoning. You'd get your toll booth workers and compare them to a control group and see if you have more problems with headache, nausea, dizziness, and fatigue. These are all symptoms associated with carbon monoxide poisoning. But what if the people who work in toll booths aren't really sicker, but because they have such a dreary job, they are more likely to complain.

To check for this, ask about muscle pain, rashes, coughing, sneezing, fevers: symptoms that are not normally associated with CO poisoning. If these are elevated in the toll booth workers, then you know that you just have a bunch of complainers on your hands. If these show little or no change, while the symptoms specific to CO poisoning do show a change, then you have stronger evidence that something real is going on.

:::

## Hill's criteria, temporality

-   Temporality
    -   A has to precede B to be a cause
    -   Advantage of prospective studies
    -   Difficult for long latency diseases
  
::: notes

If you cannot establish temporality, then you have a harder time establishing causation. 

This is easier in a prospective study. When you are recalling events in the past, it is easier to get them out of order. This is an issue I mentioned earlier with cross-sectional studies.

There were some speculations about how cancer causes smoking. This seems like a reversal of the causal model, but the argument was that some people have a genetic disposition to cancer and the same set of genes might also make them easier to get addicted. The argument doesn't hold water, of course, but you need that genetic link to keep from being totally disregarded.

Temporality is tricky for a disease that has a long latency period, one that hides quietly in your body for many years before revealing itself. Did the disease change your diet rather than your diet producing the disease?

:::

## Hill's criteria, biological gradient

-   Biological gradient
    -   Dose response relationship
    -   Rule out some, but not all confounders
    -   Hormesis and other patterns
  

::: notes

A biological gradient means that as the intensity of your intervention increases, the larger the improvement you see in your outcome. For an exposure, a biological gradient means that the greater the amount of exposure, the greater the degree of harm.

The biological gradient is often referred to as a dose-response relationship. If you have the ability to measure several levels of an intervention or exposure, it can help. Some, but not all, biasing factors tend to bias at a constant rate, not at a rate that escalates in a dose-response pattern.

For example, recall bias is a big problem in retrospective studies. People's memory of the past is influenced by what has happened to them recently. It's not that one group is making things up, but rather that the controls are more likely to overlook things.

Recall bias, though, is unlikely to be stronger in patients with a greater exposure, so if you see a gradient, with low exposures showing smaller effects than large exposures, that's good news. You can rule out recall bias and maybe selection bias and maybe even other biases if they affect your comparison more or less uniformly across the spectrum of exposures.

Hormesis is a surprising, but not too unusual pattern where you see a helpful effect for a small dose of something that is decidely harmful for larger doses. There is some evidence, for example, that a small amount of wine (e.g., one glass per day) has some beneficial effects, even though a larger amount of alcohol consumption causes all sorts of problems. So failure to see a dose response pattern is not a disqualifying event.

:::

## Hill's criteria, plausibility

-   Plausibility
    -   Biological mechanism
    -   Dependent on current state of knowledge

::: notes

Plausibility is a measure of whether a result is consistent with what we know about medicine. It is often referred to as a plausible biological mechanism.

It is commonly cited as a factor in deciding whether a result should be trusted, but in the original 1965 publication, Sir Austin Bradford Hill seems somewhat unimpressed. He points out, correctly, that our knowledge of mechanisms changes over time. 

There is also a fair amount of subjectivity in this term. Just to cite one extreme example, there was a surge about a decade ago in prayer studies where patients were randomly assigned to either receive prayers from a stranger or to a control group. There is certainly a big difference in opinion about whether it is plausible to believe in a God who intercedes in our lives when we pray to Him.

The other problem with plausibility is that it is not too hard to come up with a biological mechanism for just about anything. So oral contraceptives could have an effect on the risk of breast cancer, but the mechanism could be an adverse effect because of the estrogen in oral contraceptives, or you could just as easily come up with a mechanism that is protective because of the progestin.

In spite of Hill's reservations, a plausible mechanism is a great thing to have on your side. Lack of plausibility, however, could just mean that we haven't discovered the mechanism yet.

:::

## Hill's criteria, coherence

-   Coherence
    -   Follows natural history
    -   Consistent with biology

::: notes

The remaining criteria are less frequently cited, but I want to mention them anyway for the sake of completeness.

Coherence means that the results of the research are consistent with what you know about the natural history and biology of the disease. It sounds a bit like having a plausible mechanism, but I think that Sir Austin Bradford Hill is talking about something a bit more indirect than a mechanistic explanation.

:::

## Hill's criteria, experiment

-   Experiment

::: notes

Sir Austin Bradford Hill developed his nine criteria for settings where direct experimental manipulation of the exposure would be impossible, but sometimes you can find an indirect way to run an experiment.

There are settings called natural experiments where a change in exposure was mandated by some fluke or accident. This is not as good as randomization, but the nature of the accident was unlikely to produce serious biases. This could be a law passed to ban import of pesticides, or a change in alcohol taxes. See the Craig 2012 article in the recommended readings.

You might also be able to run an experiment with random assignment not to a particular exposure but rather to an intervention that is hoped might reduce the exposure. So, you can't randomly assign women to breast feeding versus bottle feeding, partly because it would be unethical and partly because of strong patient preference. But what you can do it to encourage every new mother to breast feed her child for six months. And then for a randomly selected subset of these patients, you would give them extra resources, such as access to a lactation consultant, free breast pumps, and regular visits by a home nurse. If those extra resources provided a significant change in breast feeding, then you would probably be able to measure improvements in the health and well-being of both the child and the mother.

:::

## Hill's criteria, analogy

-   Analogy
    -   Similar to coherence?

::: notes

This is the weakest and hardest to understand of Hill's nine criteria. It requires a creative way of thinking.

A paper by Fedak in your recommended reading suggests that the similarity in shape between carbon nanotubes and asbestos fibers might allow you to make an analogous claim about the cancer causing properties of carbon nanotubes.

:::

