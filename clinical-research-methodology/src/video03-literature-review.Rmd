---
title: "Video 3 - Literature review"
author: "Steve Simon"
output: 
  powerpoint_presentation:
    reference_doc: ../doc/template.pptx
    slide_level: 3
---

```{r echo=FALSE}
source("prelims.R", echo=FALSE)
char_limit <- 600
```

***
`r read_text("objectives03", char_max=char_limit)`

<div class="notes">

This is the video for the third week of class. 

This is what we will cover this week.

</div>

***
### What is a literature review 

Definition (from your book): "An interpretation of a selection of documents (published or unpublished) on a specific topic that involves summarization, analysis, evaluation, and synthesis of the documents."

<div class="notes">

Take a careful look at this definition.

A literature review involves summarization. You take a ten page research article and boil it down to one or two sentences.

It involves analysis. You need to gain an understanding of what is in each research paper.

It involves evaluation. You need to assess the validity of the research papers. This is synonymous with the critical appraisal step in Evidence Based Medicine.

It involves synthesis. You have to combine your knowledge of each individual study into a cohesive structure.

What all of this means is that you have to live and breath these studies. You can't summarize, analyzie, evaluate, or synthesize with only a superficial understanding of these papers.

</div>

***
### Why do a literature review?

(From your book)

+ "Identify gaps in the literature"
+ "Help to select appropriate methods for your new topic"
+ "Describe the inferences that have come from past research"
+ Other reasons???
  + Because you have to.


<div class="notes">

A literature review is a requirement for pretty much any research paper or presentation, for any IRB proposal, or for any grant proposal. So, you're probably doing this literature review out of a sense of obligation if nothing else.

But why would I or someone else insist on this literature review?

A literature review can and should influence your work. Even if you already have a strong idea of what you plan to do, keep an open mind about the direction of your research while doing the literature review. The literature review might change your mind about what is known and where the gaps in knowledge area. It may suggest an alternative research design or data analysis approach than you had first thought about. And it may change your impression of what the current state of knowledge is.

Even if the literature review does not help you, it is still of value to anyone who has to read and evaluate your research proposal. It gives them some background so they can understand the magnitude of the problem you are addressing, and what has been done and what still needs to be done to solve this problem.

</div>

***
### Contrasts to the literature review

* Annotated bibliography

  + Also requires summarization
  
  + Often requires analysis and evaluation
  
  + Lacks synthesis (no organization)

  + Strives for completeness

<div class="notes">

Let me mention a couple of things that have some similarities to a literature review, but which also have important differences.

An annotated bibliography is a great thing. It provides a fairly complete set of references with a brief summary of each reference. 

If you are thinking of starting a website or blog, consider developing an annotated bibliography. It will be a very popular resource because people want to know what they are going to click on before they actually click. It's also a lot easier to develop an annotated bibliography than your own original content.

Like a literature review, an annotated bibliography requires summarization. Usually the summaries are a bit longer in an annotated bibliography. In fact, in a literature review, if you find three articles that say the same thing, you lump them all together and talk about them as if they were one.

Annotated bibliographies are also like literature rviews in that most of them provide an analysis and evaluation of the articles.

The big difference is that an annotated bibliography does not try to synthesize the articles. It discussed each article individually, but does not try to organize them in a narrative flow (we'll talk about organizaiton in just a bit).

The other difference is that in an annotated bibliography, you usually try to be comprehensive in the studies you cite. In a literature review, if you find one or two articles that make a particular point, then you don't typically need or want to include others as well.

</div>

***
### Contrasts to the literature review

* Systematic overview

  + Systematic

  + Exhaustive search
  
  + Usually a quantitative summary
  
  + Lacks synthesis
  
<div class="notes">

A systematic overview (often called a meta-analysis, though there is a subtle distinction between the two) also has some similarities to a literature review.

The first distinguishing feature of a systematic overview is that it is systematic. It follows a pre-specified structure from a detailed protocol.  You require such rigidity because you want a systematic overview to be repeatable. With a literature review, you change how you search for articles and how you evaluate them as you go along. It is a very ad hoc approach.

A systematic overview attempts to get all studies related to a particular research hypothesis and this hypothesis is usually drawn more narrowly than a literature review. In a literature review, by contrast, you might talk first about defining stuides that define the magnitude of your health care problem and then switch to interventions that have been tested in your area. The systematic overview is likely to consider only studies within a certain time range, but your literature review might provide some much earlier studies to provide some historical context.

Systematic overviews often contain a quantitative summary (the meta-analysis) while literature reviews almost always use a qualitative approach.

Systematic overviews do not consider any synthesis (other than the quantitative summary) and just toss all of the studies into a big pot and stir.

The other distinction is that a systematic overview works with an almost obsessive fervor to identify every possible study in a topic. One of the greatest threats to the validity of a systematic overview is publication bias, and you have to work very very hard to overcome this.

For what it's worth, there has been a call in the research community to replace the literature review with a systematic overview for the benefit of an IRB submission. The systematic overview would establish whether sufficient evidence has already accumulated to make the proposed research unnecessary (and therefore unethical). This suggestion has not really been adopted anywhere, as far as I know, but it is interesting.

</div>

***
### Finding sources for your literature review

* Talk to a librarian

* Specify your scope

* Use primary sources, peer-reviewed

* Talk to a librarian

* Snowball sampling

* Iterate between writing and searching

* Talk to a librarian

<div class="notes">

Your first step is to talk to a librarian. They are experts in finding information and they love to help.

You should specify the scope of your literature review. This may change as you find out more information, but you have to start somewhere.

The almost uniform recommendation is that a literature review should only include primary sources and not any secondary source. A secondary source is an analysis of one or more research studies by someone who did not conduct the research. The primary source is written by the researchers themselves. Note that most people would consider a systematic overview to be a primary resource, even though it does not meet this particular definition.

It's hard to pin down why there is such an insistence on primary sources. One possible explanation is that different people can read the same research study and draw markedly different conclusions. So you need to read the study yourself rather than rely on somone else's opinion. A second explanation might be that the primary source is going to have a greater level of detail.

That doesn't mean you can peek at a secondary source. They are great for helping you see possible organizational structures. They also are valuable to help you "prime the pump" meaning that they can help you get a critical mass of references together right from the start.

I know that a lot of people hate Wikipedia. Just for the record, I think that Wikipedia, is a great starting point. The language is pretty accessible and they try to list a few key references.

Snowball sampling is a technical term for asking one research subject to recommend other research subjects to you. Use that same idea in your literature review. If you find an interesting paper, see if that paper's bibliography has other papers worth looking at.

You should alternate between searching and writing, especially if you are using a thematic approach. The process of writing will help you identify what parts of your literature review are well covered and what parts need more references. You may also find that your organizational themes evolve as you write, leading you to search in new areas.

It's worthwhile, as you are writing to go back and talk to a librarian.

</div>

***
### Organization

* Note cards

* Spreadsheets

* Bibliographic software

  + Endnotes

  + Zotero
  
  + Mendelay
  
  + BibTeX
  
* Talk to a librarian
  
<div class="notes">

As you are working, keep good notes. It's really easy to misplace a key reference and then waste a lot of time trying to find it again. Be liberal in what you track. The time wasted from tracking too many items does not match the time wasted from trying to refind a single lost reference.

The "low tech" approach, but one that still has many advocates is writing things down on index cards. Index cards are easy to sort and to arrange in different stacks.

Many people advocate using a spreadsheet to organize your results. As for me, I hate spreadsheets, but a lot of people who are a lot smarter than I am use them. This includes the previous instructor for this class, Mary Gerkovich. So go ahead and use a spreadsheet and I promise I won't sneer. There are too many people who are too easy to condemn things because they don't match their view of the perfect world. I hope I never become like them.

There are several excellent bibliographic software programs out there. I used Endnotes for quite a while. It is a commercial product, and I have recently tried to wean myself as much as possible from commercial software. But I wll say that I loved Endnotes when I used it.

I've also used Zotero. It scans the metadata for a website and scrapes the information that you need to build a bibliography. It used to be tied very tightly to the Firefox browser, but that has changed. You can also store information from Zotero in the cloud. I used it for quite a while and liked it, but I've stopped using it for reasons I can't explain.

I have not used Mendeley, but it has gotten good reviews, especially from some of the librarians I know. It functions quite similarly to Zotero.

BibTeX (notice the curious capitalization) is an add-on to the TeX document production system. I am using BibTeX on an off these days, but have not done all my work in it just yet. BibTeX is an open source product and it uses plain text files for storage. That's a strong trend in recent years, to store things in a file that humans can read rather than a binary format. The advantage is that you can use BibTeX easily with version control software. It also integrates nicely with R Markdown, a system that I am using more and more, not just for statistical analysis, but for the production of papers, web pages, and presentations. There's a steep learning curve to BibTeX, but if you are already using TeX, it is a natural fit. I've included a reading about BibTeX in the recommended readings section, not because I want you to use it (it is an acquired taste), but rather because I want you to undestand how it works. It takes a much different approach than some of the other systems, and I really do think it is the wave of the future.

But I promise not to sneer if you use something other than BibTeX.

</div>

***
### Scraping information from an article.

![Image from the citation link of a research article](../images/export_citation.png)

<div class="notes">

I spend a fair amount of time with cut-and-paste and plain old retyping of information on the web, but it is becoming easier these days. Most journal web sites have a link that allows you to export the citation information to various formats. It's in a different spot for different journals, unfortunately. Here is an example of getting citation information from an article I co-authored back in 2006.

</div>

***
### Summarizing

* No direct quotes.

* Contextual clues

  + Also, in addition
  
  + In contrast, on the other hand
  
<div class="notes">

This is not a hard and fast rule, but you generally want to avoid direct quotes in a literature review. In other places, direct quotes are fine, but in a literature review, it makes the writing unwieldy. 

One of the websites I visited to prepare this lecture had some interesting advice about transitional words. I lost track of which site (shame, shame on me for not keeping better track of things!). The point that they made is that a long list, study after study can easily lead the reader to feel lost in all the details. Place each study in context relative to the previously mentioned. If the study is providing further support to the results of the previous study, emphasize this with words like "also" or "in addition". If the study contrasts or contradicts the previous study, emphasize this using words like "in contrast" or "on the other hand". This is a little thing, but it does help.

</div>

***
### Example of contextual words

"Dosage compensation in mammalian females is a recognized phenomenon whereby inactivation of one X chromosome ...[1]. **However,** not all X-linked genes are inactivated. Recently, an inactivation profile...was reported by Carrel and Willard [2]. ... **Subsequently**, Lyon [3] ... enhanced our knowledge about X-chromosome inactivation..."

  + Talebizadeh et al. X chromosome gene expression in human tissues: Male and female comparisons. Genomics 2006.

<div class="notes">

Notice the contextual words here. The second reference implies something quite different than the first.

The third reference supports the perspective of the second.

Note: I'm citing my own paper here, not because the writing is better than anyone else's, but rather because it's easier to talk about something you are already familiar with.

</div>

***
### Analyzing

* More than just the abstract

  + Inconsistencies with main text
  
  + Misplaced emphasis in abstract

* Research types

  + Comparative
  
  + Associational
  
  + Descriptive (Estimate, Identify)
  
* Put in some passion
  
<div class="notes">

You can't rely on just the abstract. It's fine for tossing out papers that obviously don't fit. But the abstract is sometimes inconsistent with the text. It's easy to do--you write your  paper, then you write your abstract, then you make a last minute change in the paper and forget to update your abstract.

There's also lots of documented examples of misplaced emphasis in the abstract. The text of a paper might identify an outcome that is primary, but the abstract might talk instead about a secondary outcome because it was the only one with a small p-value.

So please read the entire paper.

Most research involves comparison, so try to use words that emphasize superiority like "improved" or "better" or that emphasize comparability like "similar" or "equivalent".

Your analysis will be quite different, of course, for descriptive studies. For these, you offer an estimate (such as "1.2 million people in the United States have diabetes") or list one or more features of a group (such as "the most commonly used drugs in transplant patients to prevent rejection are calcineurin inhibitors, antiproliferative agents, and steroids").

Don't try to be dispassionate in your analysis. It is okay to invoke emotions like surprise or disappointment. Provide guidance to magnitude with phrases like "substantial change" or "moderate improvement". You can editorialize with phrases like "landmark study". Some people overdo this, but in my experience, too many authors are too timid about their writing. The desire to appear impartial causes them to suck all the life out of their prose.

Even if others disagree with your perspective, you have given them something to react to. This is far better than expecting the reader to figure out from subtle hints what you really think.

</div>

***
### Example of descriptive and comparative analysis

"African Americans represent nearly 45% of new HIV cases each year (1–2). Due to delayed HIV diagnosis, African Americans tend to enter HIV treatment at advanced stages and die from AIDS sooner than Whites (1)."

  + Berkley-Patton et al. An HIV Testing Intervention in African American Churches: Pilot Study Findings. Ann Behav Med. 2016. 
 
<div class="notes">

This is a nice example of description where you provide an estimate (45%) followed by a comparison (advanced stages, die sooner).

</div>

***
### Example of descriptive analysis

"Studies suggest many African American faith leaders are willing to provide HIV education ...(14–17); however, their reported challenges in doing so have included church capacity issues (e.g., lack of HIV training, church-appropriate HIV materials, time, and resources), controversial church issues (e.g., condom use, premarital sex, homophobia), and HIV stigma (18–22)."

  + Berkley-Patton et al 2016. 
 
<div class="notes">

This is a nice example of a descriptive result where you mention a list of features.

Don't feel that you have to follow these writing guidelines slavishly. Use them if you are not sure how to proceed, but if you are making good writing progress without these guidelines, then ignore them.

</div>

***
### Evaluating

* No "bad" or "good" studies

  + Degrees of evidence
  
  + Weak studies better than no studies
  
* Questions you can ask

  + Do the results support the conclusion?
  
  + What are the stated limitations?
  
  + Can you place this article in "the bigger picture"?
  
<div class="notes">

When you are evaluating studies, you should comment on the quality of the studies. You may be tempted to create a dichotomy between "good" studies and "bad" studies, but this is a mistake. All studies are good, and we are glad that they get published. 

What you should comment on is how persuasive a study is. By persuasive, I mean persuasive to a clinician. Many articles are very helpful in developing theories, setting research priorities, and so forth, without being far enough along to influence clinical practice.

The strength of the evidence depends on a variety of factors. Keep in mind that no single factor, by itself, is strong enough that its presence makes a study definitive or that its absence makes the study worthless.

One exception is that you sometimes have to draw a line in the sand because of space limitations. If you have three studies and only room to talk about one of them, pick the one that uses blinding, for goodness sakes, if the other two studies are unblinded.

Where the strength of the evidence really comes into play is when you need to reconcile conflicting studies. Report both, if one is much more persuasive than the other, run with that study's conclusion.

Weak evidence is certainly better than no evidence, and you can't draw a firm conclusion that contradicts the evidence, no matter how weak. If the only studies in an area are weak, then consider this your opportunity to cite a gap in knowledge, especially if your proposed research will provide a stronger degree of evidence than what is currently out there.

Some questions that you can ask: Do you feel that the author's interpretation is supported by their data. Did they discussion limitations and are those limitations relevant to you. Have they placed their results in a bigger context?

Don't accept everything blindly just because it has been published. Become critical evaluators. Note that critical means more than just criticizing, though.



</div>

***
### Evaluating

* Positive features

  + Randomization
  
  + Blinding
  
  + Strong effect
  
  + Plausible mechanism
  
<div class="notes">

I could spend hours and hours talking about evaluating ehst your book calls "research validity". I prefer talking about how strong or how persuasive the evidence is.. This is the critical appraisal step in Evidence-Based Health Care, and I've written a whole book about it.

Let me just give a quick summary here.

Randomization is a really nice thing to have, because it largely eliminates the problem of alternate explanations like confounding that might otherwise invalidate the research. Randomization is not a panacea, though, and you don't want to become a research bigot who dismisses any research that is not randomized. I'll talk more about randomization next week.

Blinding is hiding information about who gets the drug and who gets the placebo. It's not a serious possibility in many medical studies. I have an off-color joke about this. It actually got published in a medical journal, so don't tell me that the research literature is dry and boring.

Blinding is not possible in some research studies, I say, and then offer up an example of a treatment study where one of the arms is a bilateral orchiectomy. You can't blind that study because sooner or later the patient notices that something is missing. I'll talk a bit more about blinding next week.

A strong effect is more persuasive than a weak effect. How big does an effect have to be to be strong? One commonly cited criteria is an odds ratio larger than 2. This is one of the many false dichotomies in research: an odds ratio of 2.1 is strong and an odds ratio of 1.9 is weak. But it's a start.

The reason that a strong effect is more persuasive is that it is less likely to be produced by biases. Most, but not all, biases are too small to produce an artefactual odds ratio of 2.0 or greater.

If a research finding includes a plausible scientific mechanism that's a good thing.

There's a lot more to evaluation of course. These are just a few highlights.

</div>

***
### Evaluating
  
* Negative features

  + Post hoc changes
  
  + High dropout rate
  
  + Poor compliance

* Things not to fuss over

  + Quality of the journal
  
  + Intention to treat analysis

<div class="notes">

I tend to think on the positive side, but there are a few negatives. Post hoc changes in a protocol are usually troublesome. By post hoc, I mean changes that occur in the data collection process after data collection has started or changes in the data analysis plan after some of the data has been analyzed.

A high drop out rate (and anything above 30% is high) is also troublesome.

Poor compliance with the requirements of the research is also a concern. Now please remember that your research subjects are not your slaves and they are always free to do what they think is in their best interests. If your the researcher, just document and report what happened.

There's a lot of discussion of high impact journals, but I have not seen any empirical evidence that the quality of the research is higher in those journals. It may be, or it may be that the difference is in the types of problems studied rather than in the quality of the studies themselves. 

Also, if I can editorialize here, intention to treat analysis, while it is a nice thing, is way overrated. I'll talk about intention to treat analysis next week.

</div>
  
***
### Synthesizing

* Organization of a literature review

  + Chronologic (warning: can be boring!)

  + From general to specific

  + Thematic
  
* End with your research

<div class="notes">

One way of organizing your review might by chronological. This is appealing if new theories or new approaches emerge over time. But beware, becuase a chronological list can sometimes come across as dull.

The approach I like best (and your book also likes it) is to move from the general to the specific. There are several directions you can go, but one way would be talking about the disease, talking about a particular treatment of the disease, and then talking about that treatment in a particular subpopulation. Of course, talking about the disease, then a subpopulation and then a treatment within that subpopulation also works.

You start with the general because that is what your reader is most likely to be familiar with. As you make things more specific, you draw them in to the need for your research.

Whicever organizational approach you choose, your last paragraph summarizes everything and leads into the work you plan.

</div>

***
### Example of general to specific

1st paragraph. "African Americans represent nearly 45% of new HIV cases each year (1–2)."

2nd paragraph. "The Black Church is a powerful institution with a history of mobilizing African American communities for social change (5)..."

3rd paragraph. "Studies suggest many African American faith leaders are willing to provide HIV education and testing for their church/community members (14–17)..."

  + Berkley-Patton et al 2016. 

***
### Synthesizing

* Possible themes

  + Consensus, disagreements, the unknown
  
  + Problem, old remedies, new needs
  
  + Supportive, then non-supportive
  
  + Methodologies
  
  + Theories
  
  + Schools of thought

<div class="notes">

There are more possible themes than I could mention, but here are a few examples. 

Start with consensus (questions where everyone agrees on the correct answer), then list disagrements (questions with debates among competing answers), and end with the unknown (questions with no answers yet).

Or say what the problem is, say what has already been done, and say what needs to be done.

Or offer a thesis and group your references into two sections, articles that are supportive of your thesis and articles that are not supportive.

You might organize your articles into groups sharing common methodologies. In a study of mitigation of home exposures that might exacerbate asthma, the studies might be grouped by those that study a physical intervention (like improved ventilation) and by those that study a chemical intervention (spraying for dust mites). 

In a review of behavioral change, you might organize articles by the different theories of change (Lewin, Rogers, or Spradley) that they rely on. 

Some studies of child welfare management might utilize the attachment theory while others might use crisis intervention theory or social construction theory.

It's really hard to give examples here because there are so many different thematic organizations that you can choose from.

</div>

### Some last thoughts

* Revisit your literature review after writing the discussion section of your paper.
* Standard format for a thesis. 

<div class="notes">

You will revisit your literature review after you've collected the data, written your results and written your discussion section. The discussion section talks about the strengths and weaknesses of your particluar study and places your study in a broader context. When you do this, you may notice some gaps or inconsistencies in your literature review.

There is a standard format for the literature review for a thesis. This is more detailed than what you might put in a paper.

</div>

***
