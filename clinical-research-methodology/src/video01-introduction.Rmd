---
title: "Video 01 - Introduction to Clinical Research Methods"
author: "Steve Simon"
output: 
  powerpoint_presentation:
    slide_level: 3
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../results", output_format = "all") }) 
---

```{r echo=FALSE}
source("prelims.R", echo=FALSE)
```

***

`r read_text("objectives01")`

<div class="notes">

Here are the objectives for this week.

</div>

### What is research?

* " systematic investigation, including research development, testing, and evaluation, designed to develop or contribute to generalizable knowledge"

  + [45 CFR 46.102](https://www.hhs.gov/ohrp/regulations-and-policy/regulations/45-cfr-46/index.html)

* "Disciplined method" or "disciplined inquiry"

  + "dispassionate search for truth"
  
  + not dependent on surface plausibility or the status of the author.
  
  + [Gliner, Morgan, Leech. Research Methods in Applied Settings](https://books.google.com/books/about/Research_Methods_in_Applied_Settings.html?id=R23ADAAAQBAJ).
  

<div class="notes">

Let's define the three words "clinical research methodology." Start with "research." I like the federal government's definition. This comes from the Code of Federal Regulations. Basically 45 CFR 46 is the section of the Code of Federal Regulations that set up rules and regulations for ethical conduct of research.

The key words in this definition are "generalizable knowledge." If you don't hope to extrapolate beyond the range of the data you collect, it isn't research.

There certain types of studies I like to call "warehouse studies," which is analogous to trying to find out what is in a certain storage area. Let me give an example from the time I was at Children's Mercy. They had a complaint about overbilling. In fairness to Children's Mercy that's a difficult topic. Quite honestly finding the appropriate level billing is difficult.

There were tens of thousands of records that they had to audit they didn't want to audit everything. Instead, we created a random sample of the records. The purpose of random samples NOT to generalize to other institutions. The whole idea was to try to find out how much Children's Mercy overcharged, so we could properly refund the overcharges.

This idea of generalizable knowledge is probably the dividing line between the quality improvement studies and research studies and this is very complicated. I will talk more about the later. We have a whole week dedicated to quality improvement studies. 

Gliner, Morgan, and Leech emphasize research as a disciplined method. They emphasize a dispassionate search for truth and independence from preconceived notions. A true researcher should be equally happy if they find that their hypothesis is right or wrong.

Even though internally there may be some level of disappointment, you are happy for your patients. You're interested not in burnishing your career. You're interested in finding the truth. So a good researcher rejoices whenever their research hypotheses is disproven because that's progress. You know more about what and what not to do for your patients. Negative trials are progress just as much as positive trial. I'm sure I'll talk more about that later. If you have a dispassionate search for the truth, finding out that a certain medication or certain therapy that you think really works did not work is in the best interest of your patients. 

Both definitions are good, but I like the government definition for its simplicity.

</div>
 
***

### What is clinical? What is methodology?

* Clinical: "concerned with or based on actual observation and treatment of disease in patients rather than experimentation or theory."

  + [Dictionary.com](https://www.dictionary.com/browse/clinical)

* Methodology: "a body of methods, rules, and postulates employed by a discipline : a particular procedure or set of procedures"

  + [Merriam-Webster dictionary](https://www.merriam-webster.com/dictionary/methodology)

<div class="notes">

The classic dictionary definitions for "clinical" and "methodology" work just fine. "Clinical" places the emphasis on patients and methodology is a body of rules.

Now some of you may be interested in non-clinical research, such as animal studies or computer simulations. These types of research will not be covered explicitly in this course, but there is enough commonality that you can still learn a lot of things that will help you in your research career. This also means that all of my examples will be oriented to medicine. There are people who come from outside of the medical field who take this class and they still a lot that can be gotten out of this class. Maybe 75% or more of the content is still relevant, but you just have to live with the fact that all the examples I talked about will be medical examples.

So if you're in this class and you're not a clinician, that's fine. If you animal studies, that's fine. If you do marketing research that's fine.

</div>

### Research "flavors"

+ Many different nouns, same basic concept
  + Research aim
  + Research approach
  + Research goal
  + Research hypothesis
  + Research question
  + Research topic
  
<div class="notes">

I just added this slide because I've always had trouble with this. I ask people what you are researching and I don't know what proper noun is. is it a research aim, research approach, research goal, research hypothesis, research question or research topic. There are slight and subtle differences among these terms, but I use them more or less interchangeably.

A research aim is a highly focused aspect of the research protocol or research grant. It tends to have a very narrow focus.

A research approach is really talking about the methods that you going to use.

A research goal is larger in scope than a research aim.

A research hypothesis is a term that I use more often than anything, but quite honestly a lot of research does not have a hypothesis. We need to get past that belief that if you don't have a hypothesis, you don't have research. A research hypothesis is something you postulated based on your understanding of the theory of medicine that you want to prove or disprove by collecting data. 

Research hypotheses tend to be black and white and I think sometimes it's good to think in black-and-white terms. Sometimes, though, trying to choose between only two alternatives is not a good approach to research

I need to warn you about this. If I ask you what you research hypothesis and you have a research questions, don't go all huffy on me. I use these interchangeably. I shouldn't but I do. I'll be honest: I am usually not sloppy with terminology. I am usually very precise with my words but this is one exception.

A research question is a term often used when a research study does not have a hypothesis. Here's a research question. How do children who have siblings with the chronic disease cope. The child that has a chronic disease get a lot more attention, has a lot of crises that can provoke fear and anxiety in the family, and so forth. There's no hypothesis here at all. There's no this mean is bigger than that mean, no this proportion is bigger than that proportion.

Finally a research topic is generally very broad and general.

I hope I got all those distinctions right. I may be wrong on some of the details because I do not fuss about the subtle dstinctions in these terms.

</div>

### Elements of a research hypothesis

+ PICO
  + P = patient population
  + I = intervention (or exposure)
  + C = control or comparison group
  + O = outcome
+ PICOTS
  + T = time frame
  + S = setting
  
<div class="notes">

To try to characterize research, especially research that includes a hypothesis, I look for four elements, P, I, C, and O. This comes from evidence-based medicine, the step where you ask an answerable question. In order to do a good job with evidence-based medicine, you first have to pose a question in a way that can be answered by reviewing the literature, reviewing the evidence. Okay, so the experts in evidence based medicine came up with this acronym, PICO. You don't always apply this too literally, but find that it helps.

P is the patient population: who you studied. Are you studying children, or studying the elderly. Are you studying people who present with the neck fracture? Sometimes it is not people. Sometimes, you are you studying the houses that people live in, because you are interested in environmental hazards like lead paint in the home.

I is the intervention. An intervention is when you when you change something. You try to physically intervene to mitigate the problem. You give a drug or offer a therapy. Sometimes I use the word exposure. Exposure is something that your patients endure. It's not something that you provide hoping for a cure. Second hand smoke is an exposure. Non-ionizing radiation is an exposure. Interventions are sometimes bad, but the intention is what matter. An intervention is intended to make things better, while an exposure is something that might make things worse.

C is the control or comparison group. Research hypothesis, almost always, involves some sort of comparison groups. Typically it is a control group. The control group either does not get the intervention, or they get part of the intervention only, or they get an alternate intervention.

There certain cases where you don't have a comparison group. If you are trying to assess the quality of a diagnostic test, it gets a bit harder because everyone gets the diagnostic test. You can try to force this by defining a C, but this is usually not worth the effort.

There's an extension of this acronym, PICOTS. T specifies the time frame and S specifies the setting. These are important differences between a study based in a tertiary care center rather than in a first-line clinic. I sometimes look for the T and the S, but I always look for the first four, P-I-C-O.

</div>

### Where do research ideas come from?

Ronan Conroy has an excellent summary.

* Exploring your environment.

* Don't focus prematurely on a single idea.

* Extending the ideas of others.

* Getting a research idea by reading papers.

My theory

* Irritation

<div class="notes">

There's an excellent summary of how to come up with a research idea that I was asked to host on my website. It was collated from various postings on an email discussion group by Ronan Conroy.

I have lost touch with ronan Conroy, but he and I use to correspond by Internet a lot. He's a really smart guy in Ireland who wrote a very nice summary of where do research ideas come from. He pulled a bunch of ideas from the discussion board that he was on and he wrote it up very nicely. He came to me and asked if I could post his summary on my website. I was happy to do this, because it was so well written.

His outline has four main topics. I don't want to go into too much detail, but the first suggestion is to explore your environment. Look around. Sometimes stuff is sitting right under your nose. Now there are two types of students in this class. There are students who are already deeply involved in clinical responsibilities. They may be a medical resident or fellow, they may actually have the terminal medical degree, and they want to get more involved in research. These students usually are swimming in ideas because there's all this they see every day in the clinic. 

Now I have to say I'm not good at this because I don't do clinical work. I don't see patients. I'm looking from the outside. Sometimes that's a big advantage. I can be more objective about problems, I can look at the problem more abstractly. I can bring in solutions from other disciplines. So it's good to be an outsider to some extent. But if you're like me and your background is more mathematical or more computational, you may have trouble coming up with a good research idea. You don't live in the clinic the way other students do. See if you can talk to someone who has that clinical experience and ask them for help picking a good research topic.

The other thing is to avoid focusing prematurely on a single idea. You need that branch out and not have tunnel vision.

A third approach is to extend the ideas of others. William Shakespeare was a great, great writer, wrote some wonderful plays, but he stole most of these plays from someone else. He just wrote them so much better than the original sources that that's why we remember his name today and not any of those other people.

Extending the idea of others is not plagiarism. It's not stealing. It's part of research. So, for example, there may be a a fair amount known already about how to get people to lose weight when they are physically handicapped and do not have the ability to exercise. Even so, there is always a way to improve one the currently best available interventions.

If we are talking about treatment of cancer, there are always ways we can improve the treatments. For example, you might work to reduce the side effects of some these very harsh drugs. 

If you are a beginning resarchers, the last thing you want to try to do is come up with something that's totally de novo, something that's brand-new, something that no one else has ever thought of. Few of us, and I put myself in this category, are so smart that they can develop something brand-new is never been thought of before.

The last suggesiton is closely related. Read other people's research papers. These papers have a literature review, a methods section, a  results section, and a discussion section. Look at that discussion and look at where they say "options for further research." These people are giving you free advice.

Okay, now my theory about research is a lot simpler why people do research. It's the irritation principal. They see something's wrong and it just bothers them. There are two types of wrong. There's I'm doing something right now that I know I could be doing better okay. There is also I'm doing it right, but no one else is. Either way, there's a sense of irritation. It's that they have an itch that they just have to scratch. There is something that needs to be fixed and I won't feel right until I try to fix it. That's where I think for a lot of research ideas come from. 

All these ideas are all good, but let me emphasize the importance of reading. Almost every research paper includes suggestions for further research in their discussion section. This is free advice from researchers who have proved that they can get their work published.

</div>

### Uses of clinical research

* Theory development.

* Practical application.

* Development of research tools.

* Professional development.

<div class="notes">

There are many reasons to conduct research. You can develop knowledge for its own sake or for a practical application. You can also conduct research to improve the research process (this is an area I am very interested in). You can also conduct research for your own professional development. Nothing makes you a better consumer of other people's research than doing a bit of research yourself.

</div>

***

### Research dichotomies

* Dichotomies are always wrong.

  + Trichotomies.
  
  + Monochotomies.
  
  + Spectrum.
  
* But they are still useful.

  + Shorthand for others.
  
  + Guidance for statistical analysis.
  
  + Helpful for critical appraisal.
  
* No "best" level in these dichotomies.

* Mixed methods.

<div class="notes">

Your book emphasizes six (actually seven) research dichotomies. Now I believe that all dichotomies are false dichotomies. So I hate what they do, but they do have value. Some dichotomies are actually three levels (trichotomies) or more and some dichotomies are creating a division that doesn't really exist (monochotomies). 

What you might call a dichotomy may actually be a continuum like a spectrum or gradient and the choice between what goes on the left side versus what goes on the right is purely arbitrary. So, imagine a sunrise on a cloudy day. It starts out dark but gradually gets a bit brighter until eventually is becomes daylight. Where is the dividing line between day and night when you can't see when, exactly, the sun peeks over the horizon?

But these are still useful because classifying research into category A versus category B provides a shorthand that helps others understand your research. It also provides guidance as to what sort of statistical analysis is most appropriate and helps with critical appraisal of the research literature.

There is a tendency for some people to embrace one end of the dichotomy and sneer at anyone who adopts the other end. This is a big big mistake and something that I have very little patience for. A good researcher uses more than one approach to research. To say, for example, that quantitative research is "hard" science and qualitative research is "soft" science is both inaccurate and fails to recognize that both approaches are needed if we want to make any scientific progress.

There's nothing wrong with using both ends of a dichotomy in a single research study. This goes by the term "mixed methods."

</div>

***

### Schematic diagram of research

![Schematic diagram of research](../images/schematic-diagram-of-research.png)

<div class="notes">

I wanted to share this image with you early because it shows some of the dichotomies in research and how it influences what statistics you should use. I have never liked these sorts of diagrams because there are always so many exceptions to the rules they propose. But a diagram like this is still useful because it gives you a starting point for your research. Just don't let yourself be constrained too much by this diagram. It's a recommendation rather than a requirement.

We'll come back to this diagram later in this video.

</div>

***

### Theoretical versus applied

* Theoretical: no benefit to patients now.

* Applied: potential for immediate benefit.

* "Experience by itself teaches nothing... Without theory, experience has no meaning. Without theory, one has no questions to ask. Hence, without theory, there is no learning."

  + W. Edwards Deming, in The New Economics for Industry, Government, Education.

<div class="notes">

The distinction between theoretical and applied research is in when you expect to see something of value to your patients. Theoretical research has no immediate benefit to your patients, and could potentially never offer direct benefits to your patients.

There's a tendency of some applied researchers to sneer at theoretical research. Now remember that I don't want you to sneer. This is terribly wrong as this quote from W. Edwards Deming explains. Theory is what allows us to make sense of our observations of the world.

Without a theoretical framework to support it, applied research is impossible. The other value of theory is that it allows you to generalize to new settings where observations have never been made before. So I'm a big fan of theory, myself.

</div>

***
### Translational versus basic

* Basic research: "without thought of practical ends."

  + ![National Science Foundation (1953) "What is Basic Research" published in the Third Annual Report of the National Science Foundation](https://www.nsf.gov/pubs/1953/annualreports/ar_1953_sec6.pdf).
  
* Translational research: transition from "bench to bedside."

  + Called T1 research.
  
  + Next step (T2): transition from bedside to community.

  + T3, T4, T5???

<div class="notes">

I find the term "translational" to be abused a lot, but it helps to understand the original definition. The translational/basic dichotomy is not too much different from the applied/theoretical dichotomy. Basic research is research done mostly in the laboratory and "without thought of practical ends." Translational research represents a bridge between the laboratory and the real world. You'll see the phrase "from bench to bedside" used in this context. 

Some people subdivide translational research into two types with T1 research representing a bridge from the laboratory to the patient and T2 research representing a bridge from a the carefully controlled clinical trial to actual practice settings in the regular community. 

Some people further divide translational research into even more categories, T3, T4, and even T5. If you have a good resource that explains clearly what T5 research is, I'd encourage you to share it with the rest of the class.

Like every other dichotomy, it is a mistake to view one side of the dichotomy as superior to the other.

</div>

***

### Laboratory versus field.

* Laboratory: controlled setting

  + Unnatural.
  
  + Control extraneous variables.
  
* Field setting: in the clinic

* Ecologic validity: "the methods, materials and setting of the study must approximate the real-world that is being examined."

  + Source: [Wikipedia](https://en.wikipedia.org/wiki/Ecological_validity).

<div class="notes">

The second dichotomy is laboratory versus field research. Laboratory research is done in a controlled setting and has a greater level of control. The big criticism of laboratory studies is that they are "unnatural" and do not reflect how clinical care is actually provided. In fairness, almost all research has an artificiality associated with it. It's just that the laboratory is a bit more artificial than field research.

Field settings provide what the authors describe as "ecologic validity." This is a term I'd not heard before but the definition is quite simple. The Wikipedia definition is as good as any.

</div>

***

### Experimental versus observational

* Experimental

  + Researcher chooses the intervention
  
  + Allows for randomization
  
* Observational

  + Patient/doctor chooses the intervention
  
  + Groups not under anyone's control

### Participant report versus researcher observation

* Participant report.

  + Either written or oral.
  
  + Only practical approach for pain, quality of life.
  
  + Also known as Patient Reported Outcomes (PRO).
  
* Researcher observation.

  + Also includes instruments like a heart rate monitor.
  
  + Perceived as more objective.

<div class="notes">

Another dichotomy in research involves who is providing the data for the research study. If the patient is providing the data (either through an interview or through their writing), you get something "straight from the horse's mouth." There's always the concern that patients might say things to please the researcher or hide things that they might be embarrassed about. Certain things like pain and quality of life can be measured in no other way. Note that a lot of the resources for patient report appears under the acronym PRO (Patient Reported Outcome). Two good PRO references are a chapter in the NIH Collaboratory Living Textbook of Pragmatic Clinical Trials and a nice 2011 overview article in Perspectives in Clinical Research. See the readings slide for more details.

In contrast to a patient report, the physician or other care giver could provide the data. The data could also come from a machine like a blood pressure cuff or a heart rate monitor. Researcher observation is perceived by many to be more objective, but I disagree.

</div>

***

### Quantitative research versus qualitative research (1/2)

Quantitative research.

  + Synonym(?): Positivistic.
  
  + Highly structured, A priori specifications.
  
  + Separates the researcher from the research.
  
  + Data is easily represented as numbers
  
<div class="notes">

The next dichotomy is between qualitative research and quantitative research, but represents more of a philosohpical approach to research rather than any particular method of research. 

There are synonyms for these approaches: positivism for quantitative research and constructivism for qualitative research.

If anyone has good references for these approaches, please post them in the discussion board.

The quantitative/positivist approach to research tries to separate the researcher from the research process. You specify all (or as many as possible) details of the research prior to data collection so that the researcher does not influence the objective collection of data.

</div>

***

### Quantitative research versus qualitative research

* Qualitative research.

  + Synoynms(?): Constructivist, humanist.
  
  + Covers five sub-areas: phenomological, grounded theory, ethnographic, case study, and narrative research.
  
  + Open ended questions. Research guides and is guided by the research process.
  
  + Data is open ended text--difficult to represent as numbers
  
  + Measures perceptions, feelings, values
  
* Postpositivism tries to reconcile quantitative and qualitative approaches.  

<div class="notes">

The qualitative/constructivist approach to research rejects the idea of objective collection of data. Biases in the data collection process are inevitable because they are dependent on the paradigm or common way of thinking that researchers share. Rather than separate the researcher from the data collection once the protocol is writen, a qualitative approach inserts the researcher directly into the data collection and explicitly specifies the paradigm that should be used during the research process. The researcher influences the data collection and is simultaneously influenced by the data collection.

A defining characteristic of the qualitative/constructivist approach is the use of open ended questions that allow the participants to describe things from their own perspective.

There  are attempts to reconcile these two philosophies. Postpositivism (don't you love that word) recognizes that you can't totally remove the researcher from the data collection process but sees the quantitative philosophy as a way to minimize the unavoidable biases that all researchers have.

I tried to find some good resources on the web that discuss the quantitative and qualitative approaches to research, but I was not happy with any of them. I'd encourage you students to google this and share any resources that you find helpful.

Quantitative data is data that is easily reduced to a number or category, while qualitative data is not so easily reduced. This is kind of a squishy definition because you can create categories (themes) from qualitative data, but it takes a lot of effort.

Why would you ever use qualitative data if it takes more effort? Qualitative data offers a richness that cannot often get captured by quantitative data.

</div>

***

### Quote in support of quantitative data

* "When you can measure what you are speaking about, and express it in numbers, you know something about it, when you cannot express it in numbers, your knowledge is of a meager and unsatisfactory kind; it may be the beginning of knowledge, but you have scarely, in your thoughts advanced to the stage of science."

  + Lord Kelvin, as quoted at [Goodreads](https://www.goodreads.com/quotes/166961-when-you-can-measure-what-you-are-speaking-about-and)
  
* "The individual source of the statistics may easily be the weakest link. Harold Cox tells a story of his life as a young man in India. He quoted some statistics to a Judge, an Englishman, and a very good fellow. His friend said, Cox, when you are a bit older, you will not quote Indian statistics with that assurance. The Government are very keen on amassing statistics—they collect them, add them, raise them to the nth power, take the cube root and prepare wonderful diagrams. But what you must never forget is that every one of those figures comes in the first instance from the chowty dar [chowkidar] (village watchman), who just puts down what he damn pleases."

  + Josiah Stamp, as quoted at [Bartleby](https://www.bartleby.com/73/1768.html)

<div class="notes">

Here's a quote that I like, though it is really too extreme. In general, I find great value in both quantitative and qualitative data. 

</div>

***

### Inferential versus descriptive analysis

* Inferential

  + Synonyms(?): Statistical, qunatitative, confirmatory.
  
  + P-values, confidence intervals
  
* Descriptive analysis.

  + Synonyms(?): Qualitative, exploratory.
  
  + Verbal summaries.

  + Numeric measures other than p-values and confidence intervals
  
  
<div class="notes">

Your book uses the adjectives quantitative and qualitative yet one more time to describe the analysis. Possible synonyms for quantitative analysis are statistical analysis and inferential analysis. I dislike the term "statistical analysis" because it fails to recognize the wide range of statistical analyses that can be done.

I tend to view this dichotomy as inferential statistics (statistics used to test a research hypothesis) versus descriptive statistics (statistics used to describe without a particular test in mind). The former includes p-values and confidence intervals, while the latter includes means, medians, ranges, standard deviations, and percentages.

I suspect that your book would draw the line further to one side. Means and percentages are numeric summaries and are therefore part of quantitative analysis, according to your book. This limits qualitative analysis to a verbal descriptions of the data.

I dislike this attempt to overload the words "quantitative" and "qualitative" with research approaches, data types and analysis methods. I will try to avoid these adjectives and use an appropriate synonym instead.

</div>

***
### Inductive versus deductive

* Not the same as inductive/deductive reasoning.

* Deductive: use theory to test a specific hypothesis

  + from general to specific.
  
* Inductive: collect specific facts to build a theory

  + from specific to general.
  
  + often relies on qualitative research (grounded theory)

<div class="notes">

Another important dichotomy is deductive versus inductive research. Note that this is not quite the same thing as inductive versus deductive reasoning.

With deductive research, you rely on a broad theory to identify specific hypotheses to test. You are moving from a general knowledge base to identify and test specific hypotheses that the theory would predict.

Inductive research collects specific facts and uses them to develop a novel theory. You are moving from the specific to the general. Often (but not always), an inductive research project relies on qualitative methods in general and a grounded theory approach.

</div>

***
### Interrelationships

* Examples of typical associations

  + Laboratory research and theoretical research.
  
  + Constructivist research and subjective data.
  
* Plenty of exceptions, though.

* Mixed methods studies.

  + Combination of constructivist and positivist approaches.
  
  + Sometimes called triangulation.

* Pragmatic approach.

<div class="notes">

With six dichotomies, there are two raised to the sixth power or 64 different types of research. But some of these dichotomies are more likely to appear together than others.

A laboratory study, for example, is fairly likely to be a theoretical study and a field study is fairly likeloy to be an applied study. A constructivist (qualitative) approach to research is fairly likely to collect subjective (qualitative) data.

But there are plenty of exceptions to these associations. Some field studies are theoretical and some lab studies are applied. A qualitative approach to research might often require the collection of quantitative data.

The term mixed methods means a mixture of both ends of the dichotomy: a collection of both quantitative and qualitative data, for example. 

There is a term, triangulation, which is worth mentioning here, though it is not in your book. Have you ever wondered how a sailboat can sail into the wind? If the wind is coming from the west, how can you get a sailboat to go west? You sail for a short while to the northwest and then changes to turn southwest. Enough alternating, and you end up heading due west, not as fast as you'd like but you do end up getting there.

Triangulation in research is alternating between a constructivist approach that generates research ideas and a positivist approach that tests these new ideas. This leads to an exploration of more research ideas, more tests of those ideas, and so forth.

At the end of the chapter, your book offers what I think is a thoughtful choice: the pragmatic approach. A good researcher does not specialize in one particular type of research, but uses whatever approach is best for the particular research question.

I need to emphasize again that you never stand at one end of a dichotomy and criticize the other end. Don't be an applied researcher who sneers at theoretical research. Don't be a qualitative researcher who sneers at a quantitative approach.

</div>

### Schematic diagram of research

![Schematic diagram of research](../images/schematic-diagram-of-research.png)

<div class="notes">

Here's that diagram again. The "quantitative" parts of the dichotomy (positivist approach, objective data, and inferential statistics) tend to congregate on the left side of this chart and the "qualitative" parts of the dichotomy (constructivist approach, subjective data, and descriptive statistics) tend to congregate on the right side of this chart.

Don't take this chart as a mandate, and certain research approaches are not confined unfailingly to one region or one path on this diagram. But when the seemingly infinite number of choices that you face in designing a research study can lead you to despair, the ability to focus on a smaller number of choices can help a lot.

</div>


