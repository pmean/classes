---
title: "5502 module 02 demonstration program"
format: 
  html:
    embed-resources: true
editor: source
execute: 
  error: true
---

## File details

This program was written by Steve Simon on 2025-01-23 and is placed in the public domain. You can use this program any way you please.

This program reads [fat.csv][ref-fat-csv],a dataset that compares body fat measurements to girth measurements at various body locations. Refer to the [data dictionary][ref-fat-yaml] for a more detailed description.

[ref-fat-csv]: https://github.com/pmean/data/blob/main/files/fat.csv
[ref-fat-yaml]: https://github.com/pmean/data/blob/main/files/fat.yaml

```{r}
#| label: setup
#| message: false
#| warning: false

library(car)
library(glue)
library(tidyverse)
library(broom)

R.version.string
Sys.Date()
```

#### Comment on the code

The [car][ref-car] package provides some helpful functions for various regression models. This an acronym for Companion to Applied Regression, referring to the book, An R Companion to Applied Regression by John Fox and Sanord Weisberg. In this particular program, we use the vif function in car to produce variance inflation factors.

[ref-car]: https://CRAN.R-project.org/package=car 

## Intermediate files

-   fat: original data from fat.csv
-   m0: linear regression with just an intercept
-   m1: linear regression using abdomen to predict fat_b
-   m2: linear regression using chest, abdomen, hip to predict fat_b
-   m3: linear regression using all circumference measures to predict fat_b
-   m4: linear regression using age to predict fat_b
-   m5: linear regression using age and abdomen to predict fat_b
-   rsq_table: listing of r-squared values for various models
-   r2: applying augment to m2
-   r2a: r2 with all columns except .resid removed

# --- Part 1

## Read the data

```{r}
#| label: read

fat <- read_csv(
  file="../data/fat.csv",
  col_names=TRUE,
  col_types="n")
glimpse(fat)
```

#### Comments on the code

There are 19 columns of data, but they are all numeric, so a single "n" for col_types will do the trick.

## Descriptive statistics for fat_b

```{r}
#| label: descriptives-1

fat |>
  summarize(
    fat_mean=mean(fat_b),
    fat_sd=sd(fat_b),
    fat_min=min(fat_b),
    fat_max=max(fat_b))
```

#### Comments on the code

Normally you should use the na.rm argument for mean, sd, etc., but the data dictionary says that missing value codes are not needed for this data.

#### Interpretation of the output

The average patient has 19% body fat. The data has a wide range from 0% (check this value!) to 45%.

Note: while additional descriptive statistics should be calculated for all the important independent variables, we will not show them here in the interest of time and space.

## Correlations

```{r}
#| label: correlations

fat |>
  select(
    fat_b,
    chest,
    abdomen,
    hip) |>
  cor() |>
  round(2)
```

#### Comments on the code

The [cor][ref-cor] function was discussed in Biostats-1. It does help to round the correlations aggressively.

[ref-cor]: https://stat.ethz.ch/R-manual/R-devel/library/stats/html/cor.html

#### Interpretation of the output

Not too surprisingly, there are many strong positive correlations. Patients with higher body fat tend to have higher circumferences and a larger circumference measure at one location tends to be associated with larger circumference measures at other locations.

## Scatterplot of chest circumference and body fat

```{r}
#| label: plot-chest

fat |>
  ggplot() +
  aes(x=chest, y=fat_b) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(
    x="Chest circumference (cm)",
    y="Percentage body fat",
    caption="Steve Simon, 2025-01-25, CC0")
```

#### Interpretation of the output

There is a weak positive relationship between chest circumference and percentage body fat.

## Scatterplot of abdomen circumference and body fat

```{r}
#| label: plot-abdomen

fat |>
  ggplot() +
  aes(x=abdomen, y=fat_b) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(
    x="Abdomen circumference (cm)",
    y="Percentage body fat",
    caption="Steve Simon, 2025-01-25, CC0")
```

#### Interpretation of the output

There is a somewhat stronger positive relationship between abdomen circumference and percentage body fat.

## Scatterplot of hip circumference and body fat

```{r}
#| label: plot-hip

fat |>
  ggplot() +
  aes(x=abdomen, y=fat_b) +
  geom_point() +
  geom_smooth(method="lm", se=FALSE) +
  labs(
    x="Hip circumference (cm)",
    y="Percentage body fat",
    caption="Steve Simon, 2025-01-25, CC0")
```

#### Interpretation of the output

There is a weak positive relationship between hip circumference and percentage body fat.

## Linear regression model

```{r}
#| label: regression-1

m0 <- lm(
  fat_b ~ 1, 
  data=fat)

m1 <- lm(
  fat_b ~ abdomen,
  data=fat)

m2 <- lm(
  fat_b ~ chest + abdomen + hip,
  data=fat)

m3 <- lm(
  fat_b ~ 
    neck + 
    chest + 
    abdomen + 
    hip +
    thigh +
    knee +
    ankle +
    biceps +
    forearm +
    wrist,
  data=fat)

m4 <- lm(
	fat_b ~ age, 
	data=fat)

m5 <- lm(
	fat_b ~ age + abdomen, 
	data=fat)
```

#### Comments on the code

Although it is not strictly needed for your data analysis, the first model, m0, is a null model that has no predictor variables other than an intercept.

The m1 model is a simple linear regression model using one predictor variable, abdomen circumference, to predict percentage body fat.

The m2 model uses three predictor variables, chest, abdomen, and hip circumferences. It will help us address the question whether measurements above and below the abdomen produce better predictions than using just the abdomen circumference alone.

The m3 model uses all ten circumference measurements. This model is perhaps a bit excessive, but provides an interesting comparison to the model that adds the circumferences at the extremities (neck, arms and legs) to the middle three circumferences.

## Regression coefficients

```{r}
#| label: coefficients-1

tidy(m0) |>
  mutate(
    p.value =
      case_when(
        p.value <  0.001 ~ "< 0.001",
        p.value >= 0.001 ~ as.character(round(p.value, 3))))

tidy(m1) |>
  mutate(
    p.value =
      case_when(
        p.value <  0.001 ~ "< 0.001",
        p.value >= 0.001 ~ as.character(round(p.value, 3))))

tidy(m2) |>
  mutate(
    p.value =
      case_when(
        p.value <  0.001 ~ "< 0.001",
        p.value >= 0.001 ~ as.character(round(p.value, 3))))

tidy(m3) |>
  mutate(
    p.value =
      case_when(
        p.value <  0.001 ~ "< 0.001",
        p.value >= 0.001 ~ as.character(round(p.value, 3))))
```

#### Comments on the code

The [tidy][ref-broom] function (part of the broom library), provides a nice summary of the coefficients in various statistical models in R. This includes a standardization across all these statistical models. The tidy function also takes the list that is the result of most statistical models in R and extracts the necessary information into a tibble, which makes it easier for you to manipulate the results.

One big modification that this provides is the ability to simplify the display of p-values. Very small p-values are listed as < 0.001 and the other p-values are rounded to three decimal places.

[ref-broom]: https://cran.r-project.org/web/packages/broom/vignettes/broom.html

# --- Part 2

## Analysis of variance for a null model

```{r}
#| label: anova-m0

anova(m0)
```

#### Comments on the code

The [anova][ref-anova] function takes the results of a linear regression model and creates an analysis of variance model.

Although you do not need this for a formal analysis, it is instructive to look at the analysis of variance table for a null model. It has only one row which represents unexplained variation. There is no explained variation in a null model. You do not need to specify units here and in later output from the anova function, but they are the square of the units used by the outcome variable.

[ref-anova]: https://stat.ethz.ch/R-manual/R-devel/library/stats/html/anova.lm.html

#### Interpretation of the output

There is a total amount of unexplained variation of roughly 15,100 before any variables are entered into the model.

## Analysis of variance for a one variable model

```{r}
#| label: anova-m1

anova(m0, m1)
```

#### Interpretation of the output

The unexplained variation of the null model, 15,100, can be is reduced to an unexplained variation of 5,100 by a one variable model. The one variable model has explained variation of 10,000.

The F-statistic is large and the p-value is small, indicating that the one variable model provides a statistically significant prediction of the percentage of body fat. You could state equivalently that the one variable model provides a statistically significant reduction in unexplained variation over a null model.

## Analysis of variance for a three variable model

```{r}
#| label: anova-m2

anova(m0, m2)
```

#### Interpretation of the output

The unexplained variation of the null model, 15,100, can be is reduced to an unexplained variation of 4,500 by a three variable model. The three variable model has explained variation of 10,500.

The F-statistic is large and the p-value is small, indicating that the three variable model provides a statistically significant prediction of the percentage of body fat. You could state equivalently that the one variable model provides a statistically significant reduction in unexplained variation over a null model.

## Analysis of variance for a ten variable model

```{r}
#| label: anova-m3

anova(m0, m3)
```

#### Interpretation of the output



## Calcuation of r-squared for each model

```{r}
#| label: rsq

glance(m0) |>
  bind_rows(glance(m1)) |>
  bind_rows(glance(m2)) |>
  bind_rows(glance(m3)) |>
  mutate(regression_model=glue("m{0:3}")) |>
  mutate(r.squared=round(r.squared, 2)) |>
  mutate(deviance=round(deviance)) |>
  mutate(deviance=format(deviance, big.mark=",")) |>
  select(regression_model, r.squared, deviance) -> rsq_table
rsq_table
```

#### Comments on the code

The [glance][ref06] function (part of the broom library) provides a range of summary measures for a linear regression model as well as many other statistical models.

THe [bind_rows][ref07] function (part of the dplyr/tidyverse libraries) helps to put all the results of the individual models into a single tibble.

[ref06]: https://broom.tidymodels.org/reference/glance.lm.html
[ref07]: https://dplyr.tidyverse.org/reference/bind_rows.html

#### Interpretation of the output

Unexplained variation for the null model is 15,000. A model with abdomen reduces unexplained variation to 5,000 and accounts for 66% of the variation. A model with chest, abdomen, and hips reduces unexplained variation only slightly more, down to 4,500. This model accounts for 70% of the variation. A model with every circumference reduces unexplained variation a tiny bit more, to about 4,000 and accounts for about 74% of the variation.

## Analysis of variance table

```{r}
#| label: anova


anova(m0, m1) |> tidy() 
anova(m1, m2) |> tidy()
anova(m2, m3) |> tidy()
```

#### Interpretation of the output

There is a statistically significant improvement using abdomen over the null model (m1 vs m0), as well as for using chest and hip in addition to abdomen (m2 vs m1), and for using all circumference measures over just chest, abdomen, and hip. 

# --- Part 3

## Residuals

```{r}
r2 <- augment(m2)
names(r2)
```

## Residual plots versus predicted

```{r}
#| label: fitted-plot
r2 |>
  ggplot() +
    aes(x=.fitted, y=.resid) +
    geom_point() +
    geom_smooth(method="loess") +
    xlab("Predicted values from three variable model") +
    ylab("Residuals from three variable model") +
    ggtitle("Plot drawn by Steve Simon on 2025-01-27") 
```

## Residual plots versus non-included variables

```{r}
#| label: thigh-plot

r2 |> select(.resid) -> r2a
fat |>
  bind_cols(r2a) |>
  ggplot() +
    aes(x=thigh, y=.resid) +
    geom_point() +
    geom_smooth(method="loess") +
    xlab("Thigh circumference") +
    ylab("Residuals from three variable model") +
    ggtitle("Plot drawn by Steve Simon on 2025-01-27")
```

#### Interpretation of the output

For this and the remaining plots it looks like there is no evidence that these variables might provide additional predictive power above and beyond the prediction using chest, abdomen, and hip. There is an outlier on the high end of most circumference measures that may need to be investigated.

```{r}
#| label: knee-plot
fat |>
  bind_cols(r2a) |>
  ggplot() +
    aes(x=knee, y=.resid) +
    geom_point() +
    geom_smooth(method="loess") +
    xlab("Knee circumference") +
    ylab("Residuals from three variable model") +
    ggtitle("Plot drawn by Steve Simon on 2025-01-27") 
```

```{r}
#| label: ankle-plot
fat |>
  bind_cols(r2a) |>
  ggplot() +
    aes(x=knee, y=.resid) +
    geom_point() +
    geom_smooth(method="loess") +
    xlab("Ankle circumference") +
    ylab("Residuals from three variable model") +
    ggtitle("Plot drawn by Steve Simon on 2025-01-27") 
```

```{r}
#| label: biceps-plot
fat |>
  bind_cols(r2a) |>
  ggplot() +
    aes(x=knee, y=.resid) +
    geom_point() +
    geom_smooth(method="loess") +
    xlab("Biceps circumference") +
    ylab("Residuals from three variable model") +
    ggtitle("Plot drawn by Steve Simon on 2025-01-27") 
```

```{r}
#| label: forearm-plot
fat |>
  bind_cols(r2a) |>
  ggplot() +
    aes(x=knee, y=.resid) +
    geom_point() +
    geom_smooth(method="loess") +
    xlab("Forearm circumference") +
    ylab("Residuals from three variable model") +
    ggtitle("Plot drawn by Steve Simon on 2025-01-27") 
```

```{r}
#| label: wrist-plot
fat |>
  bind_cols(r2a) |>
  ggplot() +
    aes(x=wrist, y=.resid) +
    geom_point() +
    geom_smooth(method="loess") +
    xlab("Wrist circumference") +
    ylab("Residuals from three variable model") +
    ggtitle("Plot drawn by Steve Simon on 2025-01-27") 
```

# --- Part 4

## Variance inflation factor

```{r}
#| label: vif

library(car)
vif(m2)
```

# --- Part 5

## Mediation analysis

```{r}
#| label: coefficients-2

tidy(m4) |>
  mutate(
    p.value =
      case_when(
        p.value <  0.001 ~ "< 0.001",
        p.value >= 0.001 ~ as.character(round(p.value, 3))))

tidy(m5) |>
  mutate(
    p.value =
      case_when(
        p.value <  0.001 ~ "< 0.001",
        p.value >= 0.001 ~ as.character(round(p.value, 3))))



## Save everything

```{r}
#| label: save
save(
  fat,
  m0,
  m1,
  m2,
  m3,
  m4,
  m5,
  rsq_table
  r2,
  file="../data/module02.RData")
```