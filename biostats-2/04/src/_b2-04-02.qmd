---
title: "Multiple factor analysis of variance"
format: 
  revealjs:
    slide-number: true
    embed-resources: true
editor: source
---


```{r}
#| label: 04-02-setup
#| message: false
#| warning: false

library(tidyverse)
load("../data/module04.RData")
```


## Mathematical model, 1

-   Decompose $\mu_{ij}$ into $\mu + \alpha_i + \beta_j$
    -   $\alpha_i$ is the deviation for the ith level of first factor
    -   $\beta_j$ is the deviation for the jth level of second factor
    -   Require $\alpha_1=0$ and $\beta_1=0$
    -   $\mu$ is the mean for the reference levels

::: notes
The mathematical model for two factor analysis of variance is a bit more complex than a single factor analysis of variance. You have a mean at the reference levels, mu, You also have deviations from the overall mean associated with the first factor (alpha), deviations from the overall mean associated with the second factor (beta)

There are a total of a and b categories for the two categorical independent variables.
:::

## Mathematical model, 2

-   $Y_{ijk} = \mu + \alpha_i + \beta_j +\epsilon_{ijk}$
    -   i=1,...,a levels of the first categorical variable
    -   j=1,...,b levels of the second categorical variable
    -   k=1,...,n replicates with first and second categories
-   Note: $\mu, \alpha_i, \beta_j, \epsilon_{ijk}$ are population values

::: notes
The mathematical model for two factor analysis of variance is a bit more complex than a single factor analysis of variance. You have an overall mean, mu, and deviations from the overall mean associated with the first factor (alpha), deviations from the overall mean associated with the second factor (beta) and an error term (epsilon).

There are a total of a and b categories for the two categorical independent variables.
:::

## Mathematical model, 3

-   $H_0:\ \alpha_i=0$ for all i

$\ $

-   $H_0:\ \beta_j=0$ for all j

::: notes

There are two hypotheses. The first, testing that all the alphas equal zero is effectively testing whether the first factor has no impact on the outcome. Testing that all the betas equal zero is effectively testing whether the second factor has no impact on the outcome.

:::

## Parameter estimates for the two factor model

```{r}
#| label: table-05

table_05
```

## Analysis of variance table comparing the two factor model to the null model

```{r}
#| label: table-06

table_06
```

::: notes

:::

## Analysis of variance table comparing the two factor model to the one factor model

```{r}
#| label: table-07

table_07
```

## R-squared values

```{r}
#| label: table-08

table_08
```



## Tukey post hoc test

```{r}
#| label: table-09

table_09
```


::: notes
Use the Tukey posthoc test because the sample sizes are equal across the moon phases. The results are a bit ambiguous because before and after are not statistically different, after and during are not statistically different but before and during are statistically different. This is probably due to a lack of precision and an extra year's worth of data would help quite a bit.

The analogy I use is travel time. My wife and I live in Leawood. Our son lives in Lee's Summit. A repair shop we all use is in Olathe. It is not far from Leawood to Olathe. It is not far from Leawood to Lee's Summit. But it is far from Lee's Summit to Olathe.
:::
