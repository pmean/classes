---
title: "Linear regression modules using the fev dataset"
format: 
  html:
    embed-resources: true
---

There is a [data dictionary][dd] that provides more details about the data. The program was written by Steve Simon on 2024-09-02 and is placed in the public domain.

[dd]: https://github.com/pmean/datasets/blob/master/fev.yaml

## Models

-  m1: Linear regression
   -   fev ~ sex
-  m2: Linear regression
   -   fev ~ smoke
-  m3: Linear regression
   -   fev ~ age + height

# --- Part 1: Categorical independent variables

```{r}
#| label: setup
#| message: false
#| warning: false

library(broom)
library(car)
library(tidyverse)
```

#### Comments on the code

You should always load the tidyverse library. The broom library provides the glance, tidy, and augment functions that help you with computations of linear regression models. The car library provides the vif function for measuring collinearity.

## List variable names

```{r}
#| label: names

pulmonary_names <- c(
    "age",
    "fev",
    "height",
    "sex",
    "smoke")
```

## Reading the data

```{r}
#| label: read

pulmonary <- read_csv(
  file="../data/fev.csv",
  col_names=pulmonary_names,
  col_types="nnncc")
glimpse(pulmonary)
```

## m1: Linear regression model using sex to predict fev

Is there a relationship between sex and fev? Do males tend to have larger fev values than females. This section (labelled m1) shows some simple descriptive and graphical summaries followed by a linear regression model.

## m1: Descriptive stastics for sex

```{r}
#| label: sex

pulmonary |>
	count(sex) |>
	mutate(total=sum(n)) |>
	mutate(pct=100*n/total)
```

#### Interpretation of the output

There are slightly more males (51%) than females in this sample.

## m1: Descriptive statistics for fev

```{r}
#| label: fev

pulmonary |>
  summarize(
    fev_mn=mean(fev),
    fev_sd=sd(fev),
    fev_min=min(fev),
    fev_max=max(fev))
```

#### Interpretation of the output

The average fev value, 2.6, seems reasonable. The standard deviation, 0.87, indicates a fair amount of variation. The minimum and maximum values both appear to be reasonable.

## m1: Tabular summary of the relationship between sex and fev, 1

```{r}
#| label: sex-and-fev-1

pulmonary |>
  group_by(sex) |>
	summarize(
		fev_mn=mean(fev),
		fev_sd=sd(fev))
```

#### Interpretation of the output

The average fev is 0.36 liters higher for males than females. There is very slightly more variation in the males (the standard deviation is 1.00 versus 0.65). In general, only a two or three fold change in standard deviations is worth worrying about.

## m1: Graphical summary of the relationship between sex and fev, 2

```{r}
#| label: sex-and-fev-2
#| eval: false

# This chunk of code will not be run.

pulmonary |>
  ggplot() +
  aes(sex, fev) +
	geom_boxplot() + 
  coord_flip() +
	labs(
    caption="Graph drawn by Steve Simon on 2024-09-26",
    x="Sex",
    y="Forced Expiratory Volume (liters)")
```

```{r}
#| label: sex-and-fev-3
#| fig-width: 6
#| fig.height: 1.5

pulmonary |>
  ggplot() +
	aes(fev, sex) +
  geom_boxplot() + 
  labs(
    x="Forced Expiratory Volume (liters)",
    y="Sex",
    caption="Steve Simon, 2024-09-26. CC0")
```

#### Comments on the code

I learned recently that the coord_flip function has been deprecated. That means that you can still use it for now, but its use is discouraged and it might disappear in future versions of ggplot2. The better way to handle this is to swap the x and y values in the aes function. R is smart enough to recognize that a categorical variable for y instead of x means that you want a horizontal boxplot.

Warning: if you are using number codes for your categorical variable, you need to inform R that the number codes are not a continuous variable by using the factor function. For example, if sex had codes 0 and 1, you would use
  
factor(sex, levels=0:1, labels=c("Female", "Male")))

#### Interpretation of the output

The boxplot shows the same pattern slightly larger fev values for males compared to females and slightly more variation. 

## m1: Fit the linear regression model

```{r}
#| label: m1-model

m1 <- lm(fev ~ sex, data=pulmonary)
m1
```

#### Interpretation of the output

The estimated average fev is 2.45 liters for females and 0.36 liters higher for males. This is a small, but possibly important difference.

## m1: Analysis of variance table

```{r}
#| label: m1-anova

anova(m1)
```

#### Interpretation of the output

The F-statistic, 29.6, is large, and the p-value is very small (< 0.001). Reject the null hypothesis and conclude that the average fev values are different between males and females.

## m1: R-squared

```{r}
#| label: m1-r-squared

glance(m1)$r.squared
```

#### Interpretation of the output

Sex is a very weak predictor of fev. Only 4% of the variation in fev values can be accounted for by a patient's sex.

Note the apparent contradiction between the F-ratio and R-squared. It seems like a contradiction, but it is not. The F-ratio provides lots of evidence against the null hypothesis, but this is because of the large sample size. Even though the relationship is statistically significant, it is still a very weak relationship.

## m1: Confidence intervals

```{r}
#| label: m1-ci

confint(m1)
```

#### Interpretation of the output

We are 95% confident that the difference in fev values is between 0.23 and 0.49. This is a positive difference for all values in the confidence interval, demonstrating that the average fev values are larger for males than for females. This interval is narrow indicating that there is very little sampling error. Hardly a surprise with such a large dataset (n=654).

Normally, you would follow this up with various diagnostic plots and influence measures.

## m2: Linear regression model using smoke to predict fev

Is there a relationship between smoke and fev? This section (labeled m2) shows some simple descriptive and graphical summaries followed by a linear regression model.

## m2: Descriptive statistics for smoke

```{r}
#| label: smoke

pulmonary |>
	count(smoke) |>
	mutate(total=sum(n)) |>
	mutate(pct=100*n/total)
```

#### Interpretation of the output

There are very few smokers (65 or 10%) in this sample. Descriptive statistics for fev were shown earlier.

## m2: Relationship between smoke and fev, 1

```{r}
#| label: smoke-and-fev-1

pulmonary |>
  group_by(smoke) |>
	summarize(
		fev_mn=mean(fev),
		fev_sd=sd(fev))
```

#### Interpretation of the output

Smokers have an average fev value that is 0.7 units higher than non-smokers. The standard deviations (0.85 and 0.75) demonstrate roughly the same amount of variation in the two groups.

## m2: Relationship between smoke and fev, 2

```{r}
#| label: smoke-and-fev-2
#| fig-width: 6
#| fig-height: 1.5

pulmonary |>
  ggplot() +
  aes(fev, smoke) +
  geom_boxplot() + 
	labs(
		x="Forced Expiratory Volume (liters)",
		y="Did the patient smoke?",
		caption="Steve Simon, 2024-09-26, CC0")
```

#### Interpretation of the output

The boxplot shows that smokers tend to have larger fev values than non-smokers.

## m2: Fit the linear regression model

```{r}
#| label: m2-model

m2 <- lm(fev ~ smoke, data=pulmonary)
m2
```

#### Interpretation of the output

The estimated average fev is 2.57 liters for non-smokers and 0.71 liters higher on average for smokers. This is quite a surprising result. There is a confounding variable that accounts for this strange finding, but you will have to wait until next semester for the answer.

# --- Part 2

## m3: Linear regression model using age and height to predict fev

Previous analysis has shown that age by itself is a strong predictor of fev and height by itself is a strong predictor of fev. A multiple linear regression model including both age and height should do an even better job in predicting fev. This model will also allow you to compare the relative importance of the two variables. Is fev most strongly associated with how big a child is or how old that child is?

You should always start with descriptive statistics and graphs. With two or more independent variables, you should also examine the correlations between the independent variables and their correlations with the dependent variable.

## m3: Descriptive statistics for age

```{r}
#| label: age

pulmonary |>
  summarize(
    age_mn=mean(age),
    age_sd=sd(age),
    age_min=min(age),
    age_max=max(age))
```

#### Interpretation of the output

The descriptive statistics are consistent with a pediatric study. The average age is 9.9 years. The standard deviation, 3.0, shows a large amount of variation in age (large at least for a pediatric study). The range, 3 years to 19 years, also demonstrates a large amount of variation.

## m3: Descriptive statistics for height

```{r}
#| label: height

pulmonary |>
  summarize(
    ht_mn=mean(height),
    ht_sd=sd(height),
    ht_min=min(height),
    ht_max=max(height))
```

#### Interpretation of the output

The average height, 61 inches, is reasonable for a group of children with an average age of around 10 years. The standard deviation, 5.7 inches, and the range, 46 inches to 74 inches, show a moderate amount of variation.

## m3: Correlations

Reduce the pulmonary data frame to just the first three columns before computing correlations.

```{r}
#| label: corr

pulmonary |>
  select(height, age, fev) |> 
  cor()
```

#### Interpretation of the output

The two independent variables, age and ht, are both strongly correlated with fev (r=0.76 and 0.87). They are also strongly correlated with one another (r=0.79).

## m3: Predicting fev using age and ht

```{r}
#| label: m3

m3 <- lm(fev ~ age + height, data=pulmonary)
m3
```

#### Interpretation of the output

The estimated average fev value increases by 0.05 liters for each increase of one year in age, holding height constant. The estimated average fev value increases by 0.11 liters for every increase of one inch in height. The estimated average fev is -4.6 for a patient of age zero with a height of zero inches. This is clearly and extrapolation beyond the range of the data.

## m3: Confidence intervals

```{r}
#| label: m3-ci

confint(m3)
```

#### Interpretation of the output

We are 95% confident that the estimated average fev value increases between 0.036 and 0.072 liters for each increase of one year of age holding height constant. Conclude that there is a positive relationship between fev and age.

We are 95% confident that the estimated average fev value increases between 0.10 and 0.12 liters for each increase of one inch in patient's height holding age constant. Conclude that there is a positive relationship between height and fev.

Both intervals are narrow, showing that sampling error is small for this dataset.

Do not interpret the confidence interval for the intercept.

## m3: Analysis of variance table

```{r}
#| label: m3-anova

anova(m3)
```

#### Interpretation of the output

The sum of squares total (SST) is 280.9 + 95.3 + 114.7 = 490.9. Only a small portion of the variation (114.7) is unexplained variation. The F-ratio is much larger than 1, and the p-value is less than 0.001. You can conclude that the combination of age and height helps significantly in predicting fev.

## m3: R-squared

```{r}
#| label: m3-r-squared

glance(m3)$r.squared
```

#### Interpretation of the output

Roughly 77% of the variation in fev can be explained by the combination of the age and height of the patients.

# --- Part 3

## m3: Diagnostic plots, 1

```{r}
#| label: diagnostic-1

r3 <- augment(m3)
r3 |>
	ggplot(aes(sample=.resid)) +
	  stat_qq() +
	  labs(
	  	caption="Steve Simon, 2024-09-30, CC0")
```

#### Interpretation of the output

The assumption of normality seems to be reasonably satisfied.

## m3: Diagnostic plots, 2

```{r}
#| label: diagnostic-2

r3 |>
  ggplot() +
  aes(x=.resid) +
	geom_histogram(
    binwidth=0.2,
    color="black",
    fill="white") +
	labs(
		x="Residuals from m3 regression",
		caption="Steve Simon, 2024-09-25 CC0")
```

#### Interpretation of the output

Same interpretation as above.

## m3: Diagnostic plots, 3

```{r}
#| label: diagnostic-3

r3 |>
  ggplot() +
	aes(x=.fitted, y=.resid) +
  geom_point() +
	labs(
		x="Predicted values from m3 regression",
		y="Residuals from m3 regression",
		caption="Steve Simon, 2024-09-25 CC0")
```

#### Interpretation of the output

There appears to be some evidence of non-linearity. There is definitely evidence of heterogeneity.

## m3: Influential data points, 1

```{r}
#| label: influence-1

n <- nrow(r3)
p <- 3 # two slopes + one intercept
r3 |> filter(.hat > 3*p/n)
```

#### Interpretation of the output

There are many influential data points in the model. The first is someone very short for their age. The remainder are older kids, some with below average heights for their age and others with above average heights. 

## m3: Influential data points, 2

```{r}
#| label: influence-2

r3 |> 
  filter(abs(.std.resid) > 3)
```

#### Interpretation of the output

The largest residuals are associated with taller kids of any age.

## m3: Influential data points, 3

```{r}
#| label: influence-3

r3 |> 
  filter(.cooksd > 1)
```

#### Interpretation of the output

In spite of the concerns with leverage and studentized residuals, none of these combine to create a serious concern about overly influential data. In other words, neither the outliers in the independent variables, nor the outliers in the residuals cause a very large shift in the regression line if they are removed.

## m3: Variance inflation factor

```{r}
#| label: vif

vif(m3)
```

#### Comments on the code

The vif function is part of the car library.

#### Interpretation of the output

Although age and height are correlated, they are not correlated to a strong enough degree to cause concern. You would need to see a variance inflation factor of 10 or more to warrant any serious concern.