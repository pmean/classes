---
title: "05-04, Confidence interval for the slope parameter"
format: 
  revealjs:
    slide-number: true
    embed-resources: true
editor: source
---


```{r setup-4}
#| message: false
#| warning: false
library(broom)
library(tidyverse)
load("../data/module05.RData")
```

## Confidence intervals, 1

-   Population model
    -   $Y_i=\beta_0+\beta_1 X_i + \epsilon_i,\ i=1,...,N$
-   Sample estimates
    -   $b_1=\frac{\Sigma(X_i-\bar{X})(Y_i-\bar{Y})}{\Sigma(X_i-\bar{X})^2}$
    -   $b_0=\bar{Y}-b_1\bar{X}$
   
## Confidence intervals, 2

-   Standard error (se)
    -   $se(b_1)=\sqrt{\frac{MSE}{(n-1) S_x^2}}$
-   Confidence interval for $\beta_1$
    -   $b_1 \pm t\ se(b_1)$
    
## Confidence intervals, 3

```{r confidence-interval}
confint(m1)
```

## Hypothesis test, 1

-   $H_0:\ \beta_1=0$
-   $H_1:\ \beta_1 \ne 0$
    -   Accept $H_0$ if $T=\frac{b_1}{se(b_1)}$ is close to zero
    -   $\ $ or Accept $H_0$ if the confidence interval includes zero
    -   $\ $ or Accept $H_0$ if the p-value is large

:::notes
The hypotheses involve the population parameter, $\beta_1$. To test this hypothesis, compare the sample statistic, $b_1$, to its standard error. If that ratio is close to zero, then you would accept the null hypothesis. If you see extreme values, very large negative or very large positive values, then you should reject the null hypothesis.
:::
    
## Hypothesis test, 2

```{r hypothesis-test}
tidy(m1)
```

:::notes
Here is the output for the t-test in R.
:::

## Why two different ways to test?

-   $F=T^2$
    -   Accept $H_0$ if F is close to one
    -   Accept $H_0$ if T is close to zero
-   For both tests
    -   Accept $H_0$ if p-value is large
-   F and T differ in more complex settings
    -   F is a global test of all variables
    -   T is series of separate tests of individual variables
    
:::notes
Although it seems redundant to have two different ways to test the same hypothesis, it actually becomes important for more complex settings where you are trying to predict an outcome using two or more independent variables.
:::

