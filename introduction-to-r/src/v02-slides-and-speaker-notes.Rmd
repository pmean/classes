---
title: "Module02: Data with mostly continuous variables"
author: "Steve Simon"
date: "Created 2020-02-08"
output: powerpoint_presentation
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_dir = "../results", output_format = "all") })  
---

### The tidyverse library

```{r}
library(tidyverse)
```

<div class="notes">

The tidyverse package is a collection of several different packages which provide enhancements to the R programming language. These libraries share a common programming philosophy. There are several dozen libraries in  total, but only a core set of libraries are loaded with the library(tidyverse) function. Other tidyverse packages must be loaded separately.

I recommend that you use the tidyverse library for all your programs in this class. Here are some of the libraries in core set of libraries.

</div>

### dplyr

![Hex sticker for dplyr](https://github.com/rstudio/hex-stickers/raw/master/PNG/dplyr.png)

<div class="notes">

dplyr provides a set of functions for data manipulation.

</div>

### ggplot2

![Hex sticker for ggplot2](https://github.com/rstudio/hex-stickers/raw/master/PNG/ggplot2.png)

<div class="notes">

While R has some excellent graphics capabilities built in, they are somewhat difficult to use. The ggplot2 library simplifies the process of graphing by separating the parts of a graph into different layers. It is based on a conceptual framework developed by Leland Wilkinson in his book, The Grammar of Graphics.

</div>

### magrittr

![Hex sticker for magrittr](https://github.com/rstudio/hex-stickers/raw/master/PNG/pipe.png)

<div class="notes">

magrittr provides a pipe operator. The concept of the pipe was developed first in Unix systems almost 50 years ago. The pipe operator (percent-greater than-percent) takes input from the left side of the operator and feeds it to a function listed on the right side of the operator. Pipes can be chained together. They make your code simpler and more readable.

We may or may not cover pipes in this class.

</div>

### readr

![Hex sticker for readr](https://github.com/rstudio/hex-stickers/raw/master/PNG/readr.png)

<div class="notes">

While R has many functions for reading text data, they are slow for very large files. The readr library reads text files much faster, offers some enhancements, and provides a simpler syntax.

</div>

### stringr

![Hex sticker for stingr](https://github.com/rstudio/hex-stickers/raw/master/PNG/stringr.png)

<div class="notes">

stringr simplifies the manipulation of string or text data.

</div>


### tibble

![Hex sticker for tibble](https://github.com/rstudio/hex-stickers/raw/master/PNG/tibble.png)

<div class="notes">

R has a variety of internal storage formats: arrays, lists, matrices, and data frames. We will focus mostly on data frames in this class. The tibble package offers an internal storage format, a tibble, that is very similar to a data frame, but it offers some extra features for convenience and simplicity.

</div>

### tidyr

![Hex sticker for tidyr](https://github.com/rstudio/hex-stickers/raw/master/PNG/tidyr.png)

<div class="notes">

tidyr provides a series of functions that help with data manipulation, especially for longitudinal data.

</div>

### Other packages in the tidyverse

+ In the core package
  + forcats
  + purr
+ Outside the core package
  + broom
  + lubridate
  + readxl
  + many others
  
<div class="notes">

Two other packages in the tidyverse core, forcats and purr, are for advanced applications.

Outside of the core package, some of the packages that I like are broom (which simplifies and standardizes the output from different data analysis functions)  lubridate (which simplifies the manipulaton of dates), and readxl (which reads Microsoft Excel files). There are quite a few others.

</div>

### Load tidyverse quietly

```{r}
suppressMessages(
  suppressWarnings(
    library(tidyverse)))
options(width=29)
```

<div class="notes">

Because tidyverse provides so many diagnostic messages and warnings, I have used the suppressMessages and suppressWarnings functions to avoid this in my programs. For this program, I need two more things. I need the yaml package to simplify the presentation of information from the data dictionary. I also cut the line width down to 45 characters. This is rather extreme, but it is necessary when you are producing PowerPoint documents.

</div>

### General structure of Rmarkdown

![](../images/markdown-structure.png)

<div class="notes">

Recall the general structure of an Rmarkdown file. It starts with a header, in a simple format known as YAML. Then you alternate between free text commentary and chunks of R programming statements. The chunks are surrounded by lines with three backticks and the opening set of three backticks is followed by the programming language (R) and an optional label for the chunk.

</div>


### Documentation

```{r version-and-current-date}
R.version.string
Sys.Date()
```

<div class="notes">

You should always print out the version of R that you are using and the date that the program was run. This is one of the documentation practices that you should get in the habit of using.

</div>

### Break #1
+ What have you learned
  + The tidyverse packages
  + Rmarkdown structure
+ What is coming next
  + Printing a data frame
  + Printing pieces of a data frame

### Reading existing data

```{r load}
load("../data/module02-datasets.RData")
ls()
```

<div class="notes">

After loading data, use the ls function to review what information was loaded.

</div>

### From burgers-data-dictionary.yaml

`r yaml::read_yaml("../data/burgers-data-dictionary.yaml")$description`

<div class="notes">

The first dataset that we will use in this video is "burgers."

Here is the first paragraph from the data dictionary.

It's a very small dataset, which I chose deliberately so that it would fit well on the PowerPoint slides.

</div>

### Displaying data

```{r display, comment=""}
burgers
```

<div class="notes">

R has a print function, but if you just list the name of a data frame, it will, by default, display itself.

</div>

### Showing the structure

```{r str, comment=""}
glimpse(burgers)
```

<div class="notes">

The "glimpse" function provides a description of "burgers." It is a data frame. A data frame is a rectangular grid of data. The data values in a single column of data has to be consistent: either a set of numbers, a set of dates, a set of character strings, etc. But the type of data in one column can differ from the next column.

Data frames are the workhorse of R. There are other ways of storing data: lists, arrays, vectors. But most of the data you will analyze in R will be stored in a data frame.

</div>

### Displaying a single value

```{r single-value, comment=""}
burgers[1, 1]
burgers[7, 3]
```

<div class="notes">

You can display individual data points by specifying the row and column inside square brackets.

</div>

### Displaying a single row

```{r single-row, comment=""}
burgers[1, ]
burgers[7, ]
```

<div class="notes">

You can display an entire row by specifying it and leaving the column entry blank.

</div>


### Displaying a single column (1/2)

```{r single-column-1, comment=""}
burgers[ , 1]
```

<div class="notes">

You can display an entire column similarly.

</div>

### Displaying a single column (2/2)

```{r single-column-2, comment=""}
burgers[ , 3]
```

<div class="notes">

There is an important difference in the display here. When you display a single column, it will fit more than one data point in the same row to save space. This may seem trivial and but once in a while it is not. The distinction may come up later in this class.

</div>

### Using column names

```{r column-names, comment=""}
burgers[ , "Fat"]
burgers$Fat
```

<div class="notes">

Each column has a name and you can use that name instead of the column number.

Using individual columns is so common that R developed a shorthand for it, using the dollar sign.

</div>

### Displaying multiple rows or columns

```{r multiple-1, comment=""}
burgers[1:3, ]
```

<div class="notes">

The code "1:3" means 1, 2, 3.

</div>

### Displaying multiple rows or columns

```{r multiple-2, comment=""}
burgers[ , c(1, 3)]
```

<div class="notes">

The "c" function allows you to select values that are not in a perfect sequence.

</div>

### Skipping a row or column

```{r skipping, comment=""}
burgers[ , -1]
```

<div class="notes">

A negative number means that you want to exclude that row or column. In this example, the -1 allows you to print everything except the first column.

</div>

### The head function

```{r head, comment=""}
head(burgers)
```

<div class="notes">

The "head" function displays the first five rows of data.

</div>

### The tail function

```{r tail, comment=""}
tail(burgers)
```

<div class="notes">

The "tail" function displays the last five rows of data. If there is a problem with a data set, it often shows up more obviously at the bottom of a data frame than the top.

Now using "head" or "tail" on a dataset as small as this one is silly, but these two functions are very useful for larger datasets.

</div>

### Break #2
+ What have you learned
  + Printing a data frame
  + Printing pieces of a data frame
+ What is coming next
  + Definitions of categorical and continuous data
  + The "fat" data set
  + Outliers and missing values

### Some definitions

+ Categorical = small number of possible values
+ Examples
  + Sex (Male or Female),
  + Race/ethnicity (Caucasian, African American, Hispanic, etc.),
  + Cancer stage (I, II, III, or IV),
  + Birth delivery type (Vaginal, C-section). 

<div class="notes">

A **categorical variable** is a variable that can only take on a small number of values. Each value is usually associated with a particular category.

</div>

### Some definitions
+ Continuous variable = large number of possible values
+ Examples of continuous variables are
  + Birth weight in grams,
  + Gestational age,
  + Fasting LDL level.

<div class="notes">

A **continuous variable** is a variable that can take on a large number of possible values, potentially any value in some interval.

There are some variables that are on the boundary between categorical and continuous, but it is not worth quibbling about here. 

The point to remember is that the types of graphs that you use and the types of statistics that you compute are dependent on many things, but first and foremost on whether the variables are categorical, continuous, or a mixture.

Today, you will see examples involving mostly continuous variables.

</div>

### From fat-data-dictionary.yaml

`r yaml::read_yaml("../data/fat-data-dictionary.yaml")$description`

<div class="notes">

Here is the first paragraph from the data dictionary.

</div>

### First few lines of data

```{r first-few-lines}
fat[1:5, 1:4]
```

<div class="notes">

Here are the first few lines of the data set.

</div>

### Glimpse of the data

```{r glimpse-fat}
glimpse(fat)
```

<div class="notes">

Here is a glimpse at the structure of the data.

</div>

### Some simple rules for data frames
+ Rectangular grid
+ Different types across columns
+ Single type within a column
+ Alternative ways to store data
  + Vector
  + Matrix
  + Array
  + List
  
<div class="notes">

R has many of the features of an object-oriented language, but it is not a true object-oriented programming language. There are a variety of objects in R like vectors, lists, matrices, and arrays, that are useful for storing, manipulating, and analyzing research data. We will spend most of this class using a particular object, the data frame.

The object, fat, that you just created with the read.table function is a data frame. Data frames are rectangular grids of data. Each column in the data frame has the same length. A data frame can store data of various types (numeric, character, and dates are the most common types of data). The data within a column has to have the same type, but the different columns can have different data types.

There are times when the rectangular grid of a data frame is too restrictive for your data, and R has other ways of storing this data (most notably, lists), but you will find that for most data analyses, a data frame will work just fine.

The head function shows the first few rows of the data set and the tail function shows the last few rows of the data set.

Always get in the habit of checking out the very bottom of your data frame. It's a common location for glitches.

</div>

### Variable names
+ Short but descriptive
+ Mix of letters and numbers
  + Must start with a letter
  + Avoid most symbols
+ No blanks
  + CamelCase
  + dot.delimited.names
  + underscore_delimited_names

<div class="notes">

This data set did not have a header, a line at the very top of the file that lists variable names. R uses the default names V1, V2, etc. As a general rule, you should use brief (but descriptive) names for every variable in your data set. The names should be around 8 characters long. Longer variable names make your typing tedious and much shorter variable names makes your code terse and cryptic.

You should avoid special symbols in your variable names especially symbols that are likely to cause confusion (the dash symbol, for example, which is also the symbol for subtraction). You should also avoid blanks. These rules are pretty much universal across most statistical software packages. If you violate these rules, you will find out that, at a minimum, you will always have to surround your variable name by quotes to avoid problems.

There are times when you'd like to have a blank in your variable name and you can use two special symbols that you can use in R (and most other statistical pacakges), the underscore symbol (above the minus key on most keyboards) and the dot (period). These symbols create some artificial spacing that mimics the blanks. Another approach is "CamelCase" which is the mixture of upper and lower case within a variable name with each uppercase designating the beginning of a new "word".

</div>

### Break #3

+ What have you learned
  + Definitions of categorical and continuous data
  + The "fat" data set
+ What is coming next
  + Handling outliers
  + Tracking missing values
  + Histograms

### Unusual data value

```{r summary-of-ht}
summary(fat$ht)
```

<div class="notes">

There is an unusual data value, which you might not notice right away, but one of the heights is 29.5 inches. We'll talk in more detail about the summary function later, but right now I wanted to show you function because if you have an outlier in your data, you are most likely to discover it by using the summary function.

A height this small is not totally out of the realm of possibility. See, for example, 

--> http://en.wikipedia.org/wiki/List_of_shortest_people

You can use the which function to identify the row with this unusual value for further investigation. Note the use of the double equals sign and how you display a single row of a data frame.

</div>

### Which function

```{r which}
short_row <- 
  which(fat$ht==29.5)
short_row
```

### Displaying the unusual row

```{r display-unusual}
fat[short_row, ]
```

<div class="notes">

The other values look quite normal. You have to make a careful choice here. One possibility is to do nothing. If you leave the abnormal height in your data set, it may distort some of your graphs and skew some of your statistics. Still, it is often BETTER than some of the alternatives.

</div>

### Remove the outlier

```{r remove}
fat1 <- fat[-short_row, ]
summary(fat1$ht)
```

<div class="notes">

A second choice is to remove the entire row from the data frame. The - means everything EXCEPT that row.

</div>

### Set to missing

```{r missing}
fat2 <- fat
fat2[short_row,"ht"] <- NA
summary(fat2$ht)
```

<div class="notes">

A third possibility is to designate the abnormal value as missing. In R, a missing value is represented by NA.

Notice that the summary function for the ht variable notes that one of the values is missing. You should watch these missing values obsessively. This can get a bit tricky. 

There is no one method that is preferred in this setting. If you encounter an unusual value, you should discuss it with your research team, investigate the original data sources, if possible, and review any procedures for handling unusual data values that might be specified in your research protocol.

Your data set may arrive with missing values in it already. Data might be designated as missing for a variety of reasons (lab result lost, value below the limit of detection, patient refused to answer this question) and how you handle missing values is way beyond the scope of this class. Just remember to tread cautiously around missing values as they are a minefield.

Notice that I store the revised data sets with the row removed and with the 29.5 replaced by a missing value in different data frames. This is good programming practice. If you ever have to make a destructive change to your data set (a change that wipes out one or more values or a change that is difficult to undo), it is good form to store the new results in a fresh spot. That way, if you get cold feet, you can easily backtrack.

We'll use the data set with the 29.5 changed to a missing value for all of the remaining analyses of this data set.

</div>

### Break #4

+ What have you learned
  + Handling outliers
+ What is coming next
  + Tracking missing values

### You cannot test missingness directly

```{r tracking-missing-1}
which(fat2$ht==NA)
```

<div class="notes">

Logic involving missing values is tricky. If you checking for equality and one of the things in the comparison is missing, then the result is neither TRUE, not FALSE, but rather missing.

Fair enough, but R takes it a bit further, and if both sides when you are checking for equality are missing, then they might both be 5 is they weren't missing or maybe one might be 5 and the other one 10. So it might be TRUE or it might be FALSE, so we're better off calling the logical result as missing.

This is called a three valued logic system and it has advantages and disadvantages. I won't get into any technical details, except to say that you should never make assumptions. Check what you do when you are working with missing values to make sure that the three valued logic system doesn't produce results that you didn't expect.

</div>

### Use is.na to test missingness

```{r tracking-missing-2}
which(is.na(fat2$ht))
```

<div class="notes">

The short term solution to the above problem is to use a special function, is.na.

The summary function will trap and remove missing values, but most other functions in R will, by default, report a result as missing if any values going into that function are missing. The philosophy in R, I suppose, is that you need to actively select an approach for handling missing values rather than relying on a lazy default.

R is also erring on the side of caution most of the time. You may not be aware that there are missing values lurking in your data, and R is going to go out of its way to remind you, unless you tell it otherwise.

This is different from SAS and SPSS, where the default options choose perfectly reasonable approaches, but approaches that don't raise concern about missingness to the degree that R does.

</div>

```{r mean-sd-1}
mean(fat2$ht)
sd(fat2$ht)
```

<div class="notes">

Read the help file for these functions (enter ?mean or ?sd at the command prompt).

Look carefully and note that the na.rm option allows you to compute the statistic after missing values are removed.

</div>

### Using the na.rm argument

```{r mean-sd-na.rm}
mean(fat2$ht,na.rm=TRUE)
sd(fat2$ht,na.rm=TRUE)
```

<div class="notes">

For univariate functions, there are only two realistic ways to handle missing values, but for bivariate and multivariate function, there are a multitude of approaches, such as pairwise deletion, listwise deletion, last observation carried forward, single imputation, and multiple imputation. There is a lot of controversy over various methods for handling missing values.

</div>

### Remember to round your results

```{r mean-sd-rounded}
round(
  mean(
    fat2$ht,
    na.rm=TRUE), 1)
round(
  sd(
    fat2$ht,
    na.rm=TRUE), 1)
```

<div class="notes">

For univariate functions, there are only two realistic ways to handle missing values, but for bivariate and multivariate function, there are a multitude of approaches, such as pairwise deletion, listwise deletion, last observation carried forward, single imputation, and multiple imputation. There is a lot of controversy over various methods for handling missing values.

</div>

### Break #5

+ What have you learned
  + Tracking missing values
+ What is coming next
  + Histograms

### Histogram with default options - code

```{r histogram-default}
histogram_framework <-
  ggplot(fat, aes(x=ht))
histogram_default <-
  histogram_framework + 
    geom_histogram()
```

<div class="notes">

A histogram is useful for displaying a continuous variable graphically.

Always start with the default option, but don't settle for it.

</div>

### Histogram with default options - saving

```{r save-histogram-default}
png("../images/histogram01.png")
histogram_default
dev.off()
```

<div class="notes">

My system for creating PowerPoint slides requires me to store any graphs in a file. It is a bit simpler if you are creating an html document. Just leave off the png function and the dev.off function.

</div>

### Histogram with default options - graph

![](../images/histogram01.png)

<div class="notes">

Here is what the graph looks like.

</div>

### Histogram with 3 unit bins - code

```{r histogram-bin}
histogram_bin_sized <- 
  histogram_framework +
    geom_histogram(binwidth=3)
```

```{r save-bin, include=FALSE}
png("../images/histogram02.png")
histogram_bin_sized
dev.off()
```

<div class="notes">

Use the "binwidth" argument to specify how wide you want your bars to be.

</div>

### Histogram with 3 unit bins - graph

![](../images/histogram02.png)

<div class="notes">

Here is what the graph looks like.

</div>

### Histogram with white fill - code

```{r histogram-white}
histogram_white <-
  histogram_framework +
  geom_histogram(
    binwidth=3, 
    fill="white",
    color="black")
```

```{r save-white, include=FALSE}
png("../images/histogram03.png")
histogram_white
dev.off()
```

<div class="notes">

The default colors in ggplot2, black bars with a black border, are terrible. At a minimum, you should use a different color for the inside (fill) and border (color). Here is how to draw white bars with a black border.

</div>

### Histogram with white fill - graph

![](../images/histogram03.png)

<div class="notes">

Here is what the graph looks like.

</div>

### Histogram with nice labels - code

```{r nice-labels}
histogram_labeled <- 
  histogram_white +
    xlab("Height in inches") +
    ylab("Frequency count") +
    ggtitle("Histogram with outlier")
```

```{r save-histogram-labeled, include=FALSE}
png("../images/histogram04.png")
histogram_labeled
dev.off()
```

<div class="notes">

This code shows how to put nice labels on the X and Y axes along with a title.

</div>

### Histogram with nice labels - graph

![](../images/histogram04.png)

<div class="notes">

Here is what the graph looks like.

There is an important pattern to note here. Graphs created with ggplot2 can be built with layers. This makes programming a bit easier and your code is also more readable.

</div>


### Correlation coefficients

+ Correlation
  + Always between -1 and 1
  + Strong positive if > 0.7
  + Strong negative if < -0.7
  + Weak positive if between 0.3 and 0.7
  + Weak negative if between -0.3 and -0.7
  + No relationship if between -0.3 and 0.3
  

<div class="notes">

The correlation coefficient is a single number between -1 and +1 that quantifies the strength and direction of a relationship between two continuous variables. As a rough rule of thumb, a correlation larger than +0.7 indicates a strong positive association and a correlation smaller than -0.7 indicates a strong negative association. A correlation between +0.3 and +0.7 (-0.3 and -0.7) indicates a weak positive (negative) association. A correlation between -0.3 and +0.3 indicates little or no association.

Don't take these rules too literally. You're not trying to make definitive statements about your data set. You are just trying to get comfortable with some general patterns that occur in your data set. A complex and definitive statistical analysis will almost certainly not agree with at least some of the preliminary correlations noted here.

</div>

### Correlation coefficient

```{r corr-1}
cor(fat2$fat_b,fat2$age)
```

<div class="notes">

You can get a matrix of correlations for every possible pair of variables. This command becomes a bit more complicated if there are some categorical variables in your data set, as you need to exclude these prior to calculating the correlation matrix. Since you are just trying to get a general feel for your data, a bit of rounding will help you. Also, you should remove the case number before calculating the correlation matrix.

</div>

### Always round your results

```{r corr-rounded}
round(cor(fat2$fat_b,fat2$age), 2)
```

<div class="notes">

You can get a matrix of correlations for every possible pair of variables. This command becomes a bit more complicated if there are some categorical variables in your data set, as you need to exclude these prior to calculating the correlation matrix. Since you are just trying to get a general feel for your data, a bit of rounding will help you. Also, you should remove the case number before calculating the correlation matrix.

</div>

### Correlation matrix - code

```{r corr-matrix}
correlation_matrix <- 
  round(cor(fat2[ ,-1]), 2)
dim(correlation_matrix)
```

<div class="notes">

Notice that the -1 in fat2 omits the first column, which is the case number, a variable that should not be incorporated in any statistical analyses.

I don't want to display the full correlation matrix because it would go off the margins of the slide. But looking at just the first eight rows and two columns, you can see something interesting. R does not know how to compute a correlation coefficient when there are missing values.

</div>

### Correlation matrix - results

```{r corr-matrix-results, echo=FALSE}
correlation_matrix[1:8, 1:2]
```

<div class="notes">

I don't want to display the full correlation matrix because it would go off the margins of the slide. But looking at just the first eight rows and two columns, you can see something interesting. R does not know how to compute a correlation coefficient when there are missing values.

</div>

### Excerpt from the help file

![](../images/help-file-cor.png)

<div class="notes">

This is two excerpts from the help file. The documentation is quite confusing, but that is because the options here are quite confusing. The two interesting options are casewise deletion (complete.obs) and pairwise deletion (pairwise.complete.obs). For the former, the row with missing values is tossed out for every correlation calculation, so that each and every correlation uses 251 rows of data rather than 252. For the latter, most correlations use all 252 rows of data, but any correlation involving height uses only 251 rows of data.

Which choice is best is beyond the scope of this class.

</div>

### Correlation with pairwise deletion - code

```{r corr-pairwise-deletion}
correlation_matrix <- 
  round(
    cor(fat2[ ,-1], 
      use="pairwise"), 2)
```

<div class="notes">

Here is what the correlation matrix looks like with pairwise deletion. Notice that you can abbreviate "pairwise-complete-obs" to just "pairwise". Actually, any abbreviation that is not ambiguous would work, so you could say "pair" or even just "p" here since none of the other choices for the use option begins with the letter "p."

</div>

### Correlation with pairwise deletion - results

```{r corr-pairwise-deletion-results, echo=FALSE}
correlation_matrix[1:8, 1:2]
```

<div class="notes">

Here is what the correlation matrix looks like with pairwise deletion. Notice that you can abbreviate "pairwise-complete-obs" to just "pairwise". Actually, any abbreviation that is not ambiguous would work, so you could say "pair" or even just "p" here since none of the other choices for the use option begins with the letter "p."

</div>

### Different parts of the correlation matrix (1/3)

```{r central-matrix}
correlation_matrix[10:12, 1:2]
```

<div class="notes">

Rounding the correlations makes them easier to read. Here are three different parts of the correlation matrix, showing the circumference measurements versus the fat measurements. 

It's something you might not notice easily if you didn't round the data.

Here is the correlation of fat measures with measures of the central part of the body.

</div>

### Different parts of the correlation matrix (2/3)

```{r leg-matrix}
correlation_matrix[13:15, 1:2]
```

<div class="notes">

Here is the correlation with measures at various parts of the leg.

</div>

### Different parts of the correlation matrix (3/3)

```{r arm-matrix}
correlation_matrix[16:18, 1:2]
```

<div class="notes">

Here is the correlations with measures at various parts of the parts of the arm.

The interesting pattern is that the strongest correlations are measurements near the middle (abdomen, chest, hip) and the correlation goes down as you move to the extremities. The lowest correlations are at the forearm, wrist, and ankle.

</div>

### Break #7

+ What have you learned
  + Histograms
+ What is coming next
  + Correlations
  + Scatterplots

### Simple scatterplot - code

```{r scatterplot01}
scatterplot_default <- 
  ggplot(fat2,
    aes(x=abdomen, y=fat_b)) +
      geom_point()
```

```{r save-scatterplot01, include=FALSE}
png(filename="../images/scatterplot01.png")
scatterplot_default
dev.off()
```

<div class="notes">

A simple and commonly used graphical approach to showing a relationship between two continuous variables is a scatterplot.

</div>

### Simple scatterplot - graph

![](../images/scatterplot01.png)

<div class="notes">

There are lots of options available to customize your graph. Here are just a few. The xlab and ylab arguments in the plot function control what is displayed on the horizontal (x) and vertical (y) axes. The pch argument control what is used as the plotting character.

</div>

### Scatterplot with labels - code

```{r scatterplot02}
scatterplot_enhanced <- scatterplot_default +
  xlab("Abdomen (cm)") +
  ylab("Fat percentage") +
  ggtitle("Figure 1.")
```

```{r save-scatterplot02, include=FALSE}
png(file="../images/scatterplot02.png")
scatterplot_enhanced
dev.off()
```

<div class="notes">

Here are some adaptations, including better labels.

</div>

### Scatterplot with labels - graph

![](../images/scatterplot02.png)

<div class="notes">

Here is what the graph looks like.

</div>

### Scatterplot with a trend line - code

```{r scatterplot03}
scatterplot_lm <- scatterplot_enhanced +
  geom_smooth(method=lm)
```

```{r save-scatterplot03, include=FALSE}
png("../images/scatterplot03.png")
scatterplot_lm
dev.off()
```

<div class="notes">

Here's the code to produce a smooth curve on top of the data points.

</div>

### Scatterplot with a linear trend line - graph

![](../images/scatterplot03.png)

<div class="notes">

Here is what the graph looks like.

</div>

### Scatterplot with smoothing - code

```{r scatterplot04}
scatterplot_loess <- scatterplot_enhanced +
  geom_smooth(method=loess)
```

```{r save-scatterplot04, include=FALSE}
png("../images/scatterplot04.png")
scatterplot_loess
dev.off()
```

<div class="notes">

Here's the code to produce a smooth curve on top of the data points.

</div>

### Scatterplot with smoothing - graph

![](../images/scatterplot04.png)

<div class="notes">

Here is what the graph looks like.

</div>

### Conclusion

+ What have you learned?
  + The tidyverse packages
  + Printing pieces of a data frame
  + Tracking missing values
  + Histograms
  + Correlations
  + Scatterplots
  + Description of the sleep data
 